{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BrainTumorDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1TmH26aNqrbqSE25B-FSn9gZ9PON9j1MQ",
      "authorship_tag": "ABX9TyOrMbkM4778dHYv8zx6QlRc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BitanSarkar/BrainTumorDetect/blob/main/BrainTumorDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m1sn0CDWPfJ"
      },
      "source": [
        "# Taking data from drive. \n",
        "# Pre-processing of data using sklearn.preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MJCys9IKslQ",
        "outputId": "04e97d39-dc26-42cd-c26b-aa8a646ede92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import cv2 as cv \n",
        "from google.colab.patches import cv2_imshow # for image display\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "DIRECTORY = r\"/content/drive/My Drive/brain_tumor_dataset\"\n",
        "CATEGORIES = [\"yes\", \"no\"]\n",
        "\n",
        "print(\"[INFO] loading images...\")\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "ctr=0\n",
        "for category in CATEGORIES:\n",
        "  path = os.path.join(DIRECTORY, category)\n",
        "  for img in os.listdir(path):\n",
        "    ctr+=1\n",
        "    img_path = os.path.join(path, img)\n",
        "    image = load_img(img_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = preprocess_input(image)\n",
        "    data.append(image)\n",
        "    labels.append(category)\n",
        "    if ctr%500==0:\n",
        "      print(\"Data loaded upto = \" + str(ctr))\n",
        "    if ctr == 3000:\n",
        "      print(\"Data Loading COMPLETED\")\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "Data loaded upto = 500\n",
            "Data loaded upto = 1000\n",
            "Data loaded upto = 1500\n",
            "Data loaded upto = 2000\n",
            "Data loaded upto = 2500\n",
            "Data loaded upto = 3000\n",
            "Data Loading COMPLETED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXuULYJVckCo"
      },
      "source": [
        "# Label Binarizer to change \"yes\", \"no\" to 1s and 0s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hb1pjSLZor8"
      },
      "source": [
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBa66OGYZSRR"
      },
      "source": [
        "# Splitting of dataset into training and testing datas and generate image augmentation as the number of images in dataset is less."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyewR2YjXDvq"
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.10, stratify=labels, random_state=42)\n",
        "aug = ImageDataGenerator(rotation_range=20,zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15,horizontal_flip=True,fill_mode=\"nearest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn_DrcUNc5ck"
      },
      "source": [
        "# Using Neurons from MobileNetV2 to create layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfFr-QAFc42t",
        "outputId": "86d6d583-5f77-40d6-cf50-45958556be1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224,3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "\n",
        "headModel = Dense(87, activation=\"relu\")(headModel) #layer 1\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "\n",
        "headModel = Dense(34, activation=\"relu\")(headModel) #layer 2\n",
        "headModel = Dropout(0.4)(headModel)\n",
        "\n",
        "headModel = Dense(13, activation=\"relu\")(headModel) #layer 3\n",
        "headModel = Dropout(0.3)(headModel)\n",
        "\n",
        "headModel = Dense(5, activation=\"relu\")(headModel)  #layer 4\n",
        "headModel = Dropout(0.2)(headModel)\n",
        "\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBKeQ8bIn4gz"
      },
      "source": [
        "#Traing on CNN using the data-set \n",
        "# Learning rate = 0.0001\n",
        "# Epochs = 1000\n",
        "# Batch size = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg98pDuhogB9",
        "outputId": "2c516cf4-9166-4064-b01c-e37f77805020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"[INFO] compiling model...\")\n",
        "\n",
        "\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS = 1000\n",
        "BS = 50\n",
        "\n",
        "\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(aug.flow(trainX, trainY, batch_size=BS), steps_per_epoch=len(trainX) // BS, validation_data=(testX, testY), validation_steps=len(testX) // BS, epochs=EPOCHS)\n",
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "[INFO] training head...\n",
            "Epoch 1/1000\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.8014 - accuracy: 0.5115WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_test_batch_end` time: 0.0541s). Check your callbacks.\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.8014 - accuracy: 0.5115 - val_loss: 0.6864 - val_accuracy: 0.5467\n",
            "Epoch 2/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.7136 - accuracy: 0.5352 - val_loss: 0.6649 - val_accuracy: 0.6067\n",
            "Epoch 3/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.6887 - accuracy: 0.5574 - val_loss: 0.6524 - val_accuracy: 0.6233\n",
            "Epoch 4/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.6663 - accuracy: 0.5956 - val_loss: 0.6366 - val_accuracy: 0.7167\n",
            "Epoch 5/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.6500 - accuracy: 0.6163 - val_loss: 0.6114 - val_accuracy: 0.7400\n",
            "Epoch 6/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.6481 - accuracy: 0.6341 - val_loss: 0.5681 - val_accuracy: 0.7767\n",
            "Epoch 7/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.6139 - accuracy: 0.6567 - val_loss: 0.5524 - val_accuracy: 0.7700\n",
            "Epoch 8/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.5966 - accuracy: 0.6630 - val_loss: 0.5100 - val_accuracy: 0.8433\n",
            "Epoch 9/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.5713 - accuracy: 0.6926 - val_loss: 0.5086 - val_accuracy: 0.8100\n",
            "Epoch 10/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.5630 - accuracy: 0.7048 - val_loss: 0.4720 - val_accuracy: 0.8500\n",
            "Epoch 11/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.5312 - accuracy: 0.7337 - val_loss: 0.4463 - val_accuracy: 0.8300\n",
            "Epoch 12/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.5340 - accuracy: 0.7319 - val_loss: 0.4219 - val_accuracy: 0.8767\n",
            "Epoch 13/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.5345 - accuracy: 0.7304 - val_loss: 0.4177 - val_accuracy: 0.8867\n",
            "Epoch 14/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.5048 - accuracy: 0.7433 - val_loss: 0.3972 - val_accuracy: 0.8900\n",
            "Epoch 15/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.4848 - accuracy: 0.7648 - val_loss: 0.3739 - val_accuracy: 0.8900\n",
            "Epoch 16/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.4832 - accuracy: 0.7678 - val_loss: 0.3639 - val_accuracy: 0.8967\n",
            "Epoch 17/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.4602 - accuracy: 0.7822 - val_loss: 0.3502 - val_accuracy: 0.9033\n",
            "Epoch 18/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.4684 - accuracy: 0.7815 - val_loss: 0.3332 - val_accuracy: 0.9000\n",
            "Epoch 19/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.4411 - accuracy: 0.8011 - val_loss: 0.3233 - val_accuracy: 0.9000\n",
            "Epoch 20/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.4397 - accuracy: 0.8037 - val_loss: 0.3131 - val_accuracy: 0.9067\n",
            "Epoch 21/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.4223 - accuracy: 0.8107 - val_loss: 0.3010 - val_accuracy: 0.9133\n",
            "Epoch 22/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.4246 - accuracy: 0.8033 - val_loss: 0.2910 - val_accuracy: 0.9233\n",
            "Epoch 23/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.4116 - accuracy: 0.8193 - val_loss: 0.2681 - val_accuracy: 0.9300\n",
            "Epoch 24/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.4129 - accuracy: 0.8259 - val_loss: 0.2630 - val_accuracy: 0.9233\n",
            "Epoch 25/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.3862 - accuracy: 0.8367 - val_loss: 0.2552 - val_accuracy: 0.9267\n",
            "Epoch 26/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.3805 - accuracy: 0.8352 - val_loss: 0.2418 - val_accuracy: 0.9267\n",
            "Epoch 27/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.3700 - accuracy: 0.8422 - val_loss: 0.2476 - val_accuracy: 0.9233\n",
            "Epoch 28/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.3600 - accuracy: 0.8637 - val_loss: 0.2325 - val_accuracy: 0.9367\n",
            "Epoch 29/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.3598 - accuracy: 0.8504 - val_loss: 0.2264 - val_accuracy: 0.9433\n",
            "Epoch 30/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.3622 - accuracy: 0.8507 - val_loss: 0.2352 - val_accuracy: 0.9433\n",
            "Epoch 31/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.3422 - accuracy: 0.8570 - val_loss: 0.2252 - val_accuracy: 0.9367\n",
            "Epoch 32/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.3392 - accuracy: 0.8596 - val_loss: 0.2212 - val_accuracy: 0.9467\n",
            "Epoch 33/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.3377 - accuracy: 0.8715 - val_loss: 0.2151 - val_accuracy: 0.9367\n",
            "Epoch 34/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.3318 - accuracy: 0.8707 - val_loss: 0.2207 - val_accuracy: 0.9500\n",
            "Epoch 35/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.3122 - accuracy: 0.8759 - val_loss: 0.2042 - val_accuracy: 0.9433\n",
            "Epoch 36/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.3015 - accuracy: 0.8800 - val_loss: 0.1930 - val_accuracy: 0.9533\n",
            "Epoch 37/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.2941 - accuracy: 0.8870 - val_loss: 0.1983 - val_accuracy: 0.9467\n",
            "Epoch 38/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2990 - accuracy: 0.8811 - val_loss: 0.1995 - val_accuracy: 0.9400\n",
            "Epoch 39/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.3135 - accuracy: 0.8819 - val_loss: 0.1933 - val_accuracy: 0.9533\n",
            "Epoch 40/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.2998 - accuracy: 0.8848 - val_loss: 0.1854 - val_accuracy: 0.9467\n",
            "Epoch 41/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.3189 - accuracy: 0.8789 - val_loss: 0.1840 - val_accuracy: 0.9567\n",
            "Epoch 42/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.2829 - accuracy: 0.8867 - val_loss: 0.1850 - val_accuracy: 0.9533\n",
            "Epoch 43/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2841 - accuracy: 0.8907 - val_loss: 0.1860 - val_accuracy: 0.9567\n",
            "Epoch 44/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.2806 - accuracy: 0.8996 - val_loss: 0.1780 - val_accuracy: 0.9600\n",
            "Epoch 45/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.2754 - accuracy: 0.8941 - val_loss: 0.1703 - val_accuracy: 0.9567\n",
            "Epoch 46/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.2811 - accuracy: 0.8948 - val_loss: 0.1738 - val_accuracy: 0.9467\n",
            "Epoch 47/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2749 - accuracy: 0.8926 - val_loss: 0.2023 - val_accuracy: 0.9467\n",
            "Epoch 48/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.2747 - accuracy: 0.8993 - val_loss: 0.1665 - val_accuracy: 0.9533\n",
            "Epoch 49/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.2741 - accuracy: 0.8963 - val_loss: 0.1616 - val_accuracy: 0.9600\n",
            "Epoch 50/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.2689 - accuracy: 0.9015 - val_loss: 0.1721 - val_accuracy: 0.9533\n",
            "Epoch 51/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2472 - accuracy: 0.9100 - val_loss: 0.1553 - val_accuracy: 0.9667\n",
            "Epoch 52/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2584 - accuracy: 0.9041 - val_loss: 0.1554 - val_accuracy: 0.9633\n",
            "Epoch 53/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.2408 - accuracy: 0.9085 - val_loss: 0.1619 - val_accuracy: 0.9633\n",
            "Epoch 54/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2575 - accuracy: 0.9070 - val_loss: 0.1588 - val_accuracy: 0.9600\n",
            "Epoch 55/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.2206 - accuracy: 0.9219 - val_loss: 0.1680 - val_accuracy: 0.9567\n",
            "Epoch 56/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2579 - accuracy: 0.9089 - val_loss: 0.1732 - val_accuracy: 0.9567\n",
            "Epoch 57/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.2271 - accuracy: 0.9170 - val_loss: 0.1716 - val_accuracy: 0.9567\n",
            "Epoch 58/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.2318 - accuracy: 0.9185 - val_loss: 0.1635 - val_accuracy: 0.9667\n",
            "Epoch 59/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.2355 - accuracy: 0.9285 - val_loss: 0.1688 - val_accuracy: 0.9600\n",
            "Epoch 60/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.2237 - accuracy: 0.9207 - val_loss: 0.1623 - val_accuracy: 0.9600\n",
            "Epoch 61/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.2402 - accuracy: 0.9215 - val_loss: 0.1813 - val_accuracy: 0.9600\n",
            "Epoch 62/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.2243 - accuracy: 0.9281 - val_loss: 0.1582 - val_accuracy: 0.9600\n",
            "Epoch 63/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2245 - accuracy: 0.9237 - val_loss: 0.1609 - val_accuracy: 0.9633\n",
            "Epoch 64/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.2081 - accuracy: 0.9289 - val_loss: 0.1651 - val_accuracy: 0.9600\n",
            "Epoch 65/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.2052 - accuracy: 0.9270 - val_loss: 0.1558 - val_accuracy: 0.9633\n",
            "Epoch 66/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2164 - accuracy: 0.9274 - val_loss: 0.1653 - val_accuracy: 0.9633\n",
            "Epoch 67/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.2047 - accuracy: 0.9244 - val_loss: 0.1562 - val_accuracy: 0.9600\n",
            "Epoch 68/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1900 - accuracy: 0.9267 - val_loss: 0.1719 - val_accuracy: 0.9600\n",
            "Epoch 69/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2093 - accuracy: 0.9385 - val_loss: 0.1477 - val_accuracy: 0.9633\n",
            "Epoch 70/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.2003 - accuracy: 0.9296 - val_loss: 0.1613 - val_accuracy: 0.9633\n",
            "Epoch 71/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.2033 - accuracy: 0.9341 - val_loss: 0.1840 - val_accuracy: 0.9500\n",
            "Epoch 72/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1977 - accuracy: 0.9330 - val_loss: 0.1833 - val_accuracy: 0.9533\n",
            "Epoch 73/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.1929 - accuracy: 0.9333 - val_loss: 0.1291 - val_accuracy: 0.9700\n",
            "Epoch 74/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1999 - accuracy: 0.9304 - val_loss: 0.1522 - val_accuracy: 0.9700\n",
            "Epoch 75/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1804 - accuracy: 0.9367 - val_loss: 0.1669 - val_accuracy: 0.9633\n",
            "Epoch 76/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.1900 - accuracy: 0.9333 - val_loss: 0.1495 - val_accuracy: 0.9667\n",
            "Epoch 77/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1746 - accuracy: 0.9459 - val_loss: 0.1521 - val_accuracy: 0.9667\n",
            "Epoch 78/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1852 - accuracy: 0.9393 - val_loss: 0.1360 - val_accuracy: 0.9767\n",
            "Epoch 79/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.1885 - accuracy: 0.9389 - val_loss: 0.1608 - val_accuracy: 0.9633\n",
            "Epoch 80/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1975 - accuracy: 0.9319 - val_loss: 0.1487 - val_accuracy: 0.9633\n",
            "Epoch 81/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1628 - accuracy: 0.9504 - val_loss: 0.1832 - val_accuracy: 0.9600\n",
            "Epoch 82/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.1641 - accuracy: 0.9485 - val_loss: 0.1413 - val_accuracy: 0.9667\n",
            "Epoch 83/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1932 - accuracy: 0.9300 - val_loss: 0.1487 - val_accuracy: 0.9633\n",
            "Epoch 84/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1636 - accuracy: 0.9463 - val_loss: 0.1509 - val_accuracy: 0.9700\n",
            "Epoch 85/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.1691 - accuracy: 0.9430 - val_loss: 0.1538 - val_accuracy: 0.9667\n",
            "Epoch 86/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1748 - accuracy: 0.9400 - val_loss: 0.1768 - val_accuracy: 0.9633\n",
            "Epoch 87/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1556 - accuracy: 0.9507 - val_loss: 0.1796 - val_accuracy: 0.9600\n",
            "Epoch 88/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1752 - accuracy: 0.9437 - val_loss: 0.1439 - val_accuracy: 0.9667\n",
            "Epoch 89/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1791 - accuracy: 0.9407 - val_loss: 0.1733 - val_accuracy: 0.9600\n",
            "Epoch 90/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1610 - accuracy: 0.9493 - val_loss: 0.2030 - val_accuracy: 0.9567\n",
            "Epoch 91/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1694 - accuracy: 0.9456 - val_loss: 0.1507 - val_accuracy: 0.9633\n",
            "Epoch 92/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1752 - accuracy: 0.9456 - val_loss: 0.1442 - val_accuracy: 0.9600\n",
            "Epoch 93/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1741 - accuracy: 0.9470 - val_loss: 0.1334 - val_accuracy: 0.9667\n",
            "Epoch 94/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.1712 - accuracy: 0.9430 - val_loss: 0.1655 - val_accuracy: 0.9600\n",
            "Epoch 95/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1432 - accuracy: 0.9548 - val_loss: 0.1655 - val_accuracy: 0.9567\n",
            "Epoch 96/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1719 - accuracy: 0.9463 - val_loss: 0.1383 - val_accuracy: 0.9633\n",
            "Epoch 97/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1552 - accuracy: 0.9478 - val_loss: 0.1296 - val_accuracy: 0.9700\n",
            "Epoch 98/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1562 - accuracy: 0.9500 - val_loss: 0.1479 - val_accuracy: 0.9633\n",
            "Epoch 99/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1561 - accuracy: 0.9489 - val_loss: 0.1741 - val_accuracy: 0.9533\n",
            "Epoch 100/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1513 - accuracy: 0.9567 - val_loss: 0.1862 - val_accuracy: 0.9533\n",
            "Epoch 101/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1624 - accuracy: 0.9441 - val_loss: 0.1458 - val_accuracy: 0.9633\n",
            "Epoch 102/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1673 - accuracy: 0.9456 - val_loss: 0.1805 - val_accuracy: 0.9600\n",
            "Epoch 103/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1470 - accuracy: 0.9467 - val_loss: 0.1550 - val_accuracy: 0.9667\n",
            "Epoch 104/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1432 - accuracy: 0.9574 - val_loss: 0.1320 - val_accuracy: 0.9767\n",
            "Epoch 105/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1454 - accuracy: 0.9537 - val_loss: 0.1505 - val_accuracy: 0.9600\n",
            "Epoch 106/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1550 - accuracy: 0.9511 - val_loss: 0.1419 - val_accuracy: 0.9600\n",
            "Epoch 107/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1462 - accuracy: 0.9519 - val_loss: 0.1592 - val_accuracy: 0.9667\n",
            "Epoch 108/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.1409 - accuracy: 0.9522 - val_loss: 0.1579 - val_accuracy: 0.9733\n",
            "Epoch 109/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1440 - accuracy: 0.9496 - val_loss: 0.1632 - val_accuracy: 0.9600\n",
            "Epoch 110/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1456 - accuracy: 0.9530 - val_loss: 0.1447 - val_accuracy: 0.9667\n",
            "Epoch 111/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1551 - accuracy: 0.9485 - val_loss: 0.1478 - val_accuracy: 0.9667\n",
            "Epoch 112/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1563 - accuracy: 0.9478 - val_loss: 0.1669 - val_accuracy: 0.9633\n",
            "Epoch 113/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.1448 - accuracy: 0.9544 - val_loss: 0.1511 - val_accuracy: 0.9633\n",
            "Epoch 114/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1473 - accuracy: 0.9504 - val_loss: 0.1586 - val_accuracy: 0.9633\n",
            "Epoch 115/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1214 - accuracy: 0.9596 - val_loss: 0.1614 - val_accuracy: 0.9633\n",
            "Epoch 116/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.1445 - accuracy: 0.9519 - val_loss: 0.1558 - val_accuracy: 0.9667\n",
            "Epoch 117/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1571 - accuracy: 0.9526 - val_loss: 0.1591 - val_accuracy: 0.9667\n",
            "Epoch 118/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1185 - accuracy: 0.9589 - val_loss: 0.1584 - val_accuracy: 0.9633\n",
            "Epoch 119/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.1313 - accuracy: 0.9596 - val_loss: 0.1486 - val_accuracy: 0.9667\n",
            "Epoch 120/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.1385 - accuracy: 0.9507 - val_loss: 0.1532 - val_accuracy: 0.9667\n",
            "Epoch 121/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1328 - accuracy: 0.9615 - val_loss: 0.1715 - val_accuracy: 0.9600\n",
            "Epoch 122/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1334 - accuracy: 0.9581 - val_loss: 0.1503 - val_accuracy: 0.9633\n",
            "Epoch 123/1000\n",
            "54/54 [==============================] - 25s 472ms/step - loss: 0.1277 - accuracy: 0.9581 - val_loss: 0.1302 - val_accuracy: 0.9700\n",
            "Epoch 124/1000\n",
            "54/54 [==============================] - 26s 473ms/step - loss: 0.1307 - accuracy: 0.9570 - val_loss: 0.1311 - val_accuracy: 0.9667\n",
            "Epoch 125/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1161 - accuracy: 0.9656 - val_loss: 0.1286 - val_accuracy: 0.9733\n",
            "Epoch 126/1000\n",
            "54/54 [==============================] - 26s 473ms/step - loss: 0.1255 - accuracy: 0.9674 - val_loss: 0.1504 - val_accuracy: 0.9633\n",
            "Epoch 127/1000\n",
            "54/54 [==============================] - 26s 473ms/step - loss: 0.1379 - accuracy: 0.9570 - val_loss: 0.1329 - val_accuracy: 0.9733\n",
            "Epoch 128/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1304 - accuracy: 0.9563 - val_loss: 0.1257 - val_accuracy: 0.9767\n",
            "Epoch 129/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1295 - accuracy: 0.9607 - val_loss: 0.1489 - val_accuracy: 0.9633\n",
            "Epoch 130/1000\n",
            "54/54 [==============================] - 26s 472ms/step - loss: 0.1373 - accuracy: 0.9511 - val_loss: 0.1479 - val_accuracy: 0.9667\n",
            "Epoch 131/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1308 - accuracy: 0.9567 - val_loss: 0.1592 - val_accuracy: 0.9600\n",
            "Epoch 132/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.1272 - accuracy: 0.9589 - val_loss: 0.1332 - val_accuracy: 0.9700\n",
            "Epoch 133/1000\n",
            "54/54 [==============================] - 25s 472ms/step - loss: 0.1126 - accuracy: 0.9644 - val_loss: 0.1593 - val_accuracy: 0.9633\n",
            "Epoch 134/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1265 - accuracy: 0.9593 - val_loss: 0.1501 - val_accuracy: 0.9700\n",
            "Epoch 135/1000\n",
            "54/54 [==============================] - 26s 473ms/step - loss: 0.1235 - accuracy: 0.9607 - val_loss: 0.1475 - val_accuracy: 0.9667\n",
            "Epoch 136/1000\n",
            "54/54 [==============================] - 26s 473ms/step - loss: 0.1125 - accuracy: 0.9667 - val_loss: 0.1994 - val_accuracy: 0.9600\n",
            "Epoch 137/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1278 - accuracy: 0.9600 - val_loss: 0.1747 - val_accuracy: 0.9567\n",
            "Epoch 138/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1399 - accuracy: 0.9537 - val_loss: 0.1292 - val_accuracy: 0.9767\n",
            "Epoch 139/1000\n",
            "54/54 [==============================] - 26s 472ms/step - loss: 0.1026 - accuracy: 0.9656 - val_loss: 0.1809 - val_accuracy: 0.9633\n",
            "Epoch 140/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1130 - accuracy: 0.9615 - val_loss: 0.1574 - val_accuracy: 0.9667\n",
            "Epoch 141/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1235 - accuracy: 0.9619 - val_loss: 0.1278 - val_accuracy: 0.9767\n",
            "Epoch 142/1000\n",
            "54/54 [==============================] - 26s 473ms/step - loss: 0.1013 - accuracy: 0.9659 - val_loss: 0.1507 - val_accuracy: 0.9700\n",
            "Epoch 143/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1217 - accuracy: 0.9574 - val_loss: 0.1363 - val_accuracy: 0.9667\n",
            "Epoch 144/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.1040 - accuracy: 0.9707 - val_loss: 0.1434 - val_accuracy: 0.9733\n",
            "Epoch 145/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.1183 - accuracy: 0.9637 - val_loss: 0.1519 - val_accuracy: 0.9633\n",
            "Epoch 146/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1118 - accuracy: 0.9626 - val_loss: 0.1612 - val_accuracy: 0.9700\n",
            "Epoch 147/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1325 - accuracy: 0.9530 - val_loss: 0.1406 - val_accuracy: 0.9667\n",
            "Epoch 148/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1174 - accuracy: 0.9644 - val_loss: 0.1366 - val_accuracy: 0.9700\n",
            "Epoch 149/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.1123 - accuracy: 0.9667 - val_loss: 0.1746 - val_accuracy: 0.9633\n",
            "Epoch 150/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.1029 - accuracy: 0.9659 - val_loss: 0.1675 - val_accuracy: 0.9633\n",
            "Epoch 151/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.1077 - accuracy: 0.9663 - val_loss: 0.1597 - val_accuracy: 0.9667\n",
            "Epoch 152/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.1243 - accuracy: 0.9641 - val_loss: 0.1533 - val_accuracy: 0.9667\n",
            "Epoch 153/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0946 - accuracy: 0.9715 - val_loss: 0.1522 - val_accuracy: 0.9700\n",
            "Epoch 154/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.1109 - accuracy: 0.9615 - val_loss: 0.1320 - val_accuracy: 0.9733\n",
            "Epoch 155/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.1276 - accuracy: 0.9596 - val_loss: 0.1160 - val_accuracy: 0.9733\n",
            "Epoch 156/1000\n",
            "54/54 [==============================] - 26s 490ms/step - loss: 0.0995 - accuracy: 0.9685 - val_loss: 0.1294 - val_accuracy: 0.9733\n",
            "Epoch 157/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.1135 - accuracy: 0.9637 - val_loss: 0.1211 - val_accuracy: 0.9700\n",
            "Epoch 158/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0987 - accuracy: 0.9678 - val_loss: 0.1510 - val_accuracy: 0.9733\n",
            "Epoch 159/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.1087 - accuracy: 0.9674 - val_loss: 0.1793 - val_accuracy: 0.9600\n",
            "Epoch 160/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0994 - accuracy: 0.9733 - val_loss: 0.1514 - val_accuracy: 0.9633\n",
            "Epoch 161/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.1021 - accuracy: 0.9648 - val_loss: 0.1350 - val_accuracy: 0.9733\n",
            "Epoch 162/1000\n",
            "54/54 [==============================] - 27s 495ms/step - loss: 0.0993 - accuracy: 0.9678 - val_loss: 0.1382 - val_accuracy: 0.9667\n",
            "Epoch 163/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.1179 - accuracy: 0.9630 - val_loss: 0.1310 - val_accuracy: 0.9667\n",
            "Epoch 164/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.1155 - accuracy: 0.9633 - val_loss: 0.1249 - val_accuracy: 0.9733\n",
            "Epoch 165/1000\n",
            "54/54 [==============================] - 27s 493ms/step - loss: 0.0957 - accuracy: 0.9670 - val_loss: 0.1261 - val_accuracy: 0.9733\n",
            "Epoch 166/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0974 - accuracy: 0.9704 - val_loss: 0.1790 - val_accuracy: 0.9567\n",
            "Epoch 167/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.1105 - accuracy: 0.9663 - val_loss: 0.1284 - val_accuracy: 0.9700\n",
            "Epoch 168/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.1096 - accuracy: 0.9633 - val_loss: 0.1432 - val_accuracy: 0.9733\n",
            "Epoch 169/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.1192 - accuracy: 0.9604 - val_loss: 0.1067 - val_accuracy: 0.9767\n",
            "Epoch 170/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.1116 - accuracy: 0.9674 - val_loss: 0.1481 - val_accuracy: 0.9633\n",
            "Epoch 171/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0965 - accuracy: 0.9681 - val_loss: 0.1460 - val_accuracy: 0.9667\n",
            "Epoch 172/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0988 - accuracy: 0.9674 - val_loss: 0.1562 - val_accuracy: 0.9600\n",
            "Epoch 173/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.1009 - accuracy: 0.9678 - val_loss: 0.1186 - val_accuracy: 0.9733\n",
            "Epoch 174/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.1087 - accuracy: 0.9637 - val_loss: 0.1493 - val_accuracy: 0.9633\n",
            "Epoch 175/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0988 - accuracy: 0.9693 - val_loss: 0.1415 - val_accuracy: 0.9733\n",
            "Epoch 176/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.1065 - accuracy: 0.9704 - val_loss: 0.1358 - val_accuracy: 0.9700\n",
            "Epoch 177/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.1062 - accuracy: 0.9663 - val_loss: 0.1271 - val_accuracy: 0.9733\n",
            "Epoch 178/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.1112 - accuracy: 0.9652 - val_loss: 0.1018 - val_accuracy: 0.9767\n",
            "Epoch 179/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.1033 - accuracy: 0.9674 - val_loss: 0.1047 - val_accuracy: 0.9767\n",
            "Epoch 180/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.1011 - accuracy: 0.9648 - val_loss: 0.1147 - val_accuracy: 0.9800\n",
            "Epoch 181/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0924 - accuracy: 0.9681 - val_loss: 0.1122 - val_accuracy: 0.9767\n",
            "Epoch 182/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0970 - accuracy: 0.9693 - val_loss: 0.1182 - val_accuracy: 0.9767\n",
            "Epoch 183/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0871 - accuracy: 0.9678 - val_loss: 0.1245 - val_accuracy: 0.9800\n",
            "Epoch 184/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0999 - accuracy: 0.9704 - val_loss: 0.1132 - val_accuracy: 0.9800\n",
            "Epoch 185/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.1013 - accuracy: 0.9693 - val_loss: 0.1189 - val_accuracy: 0.9700\n",
            "Epoch 186/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.1082 - accuracy: 0.9678 - val_loss: 0.1322 - val_accuracy: 0.9667\n",
            "Epoch 187/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.1037 - accuracy: 0.9630 - val_loss: 0.1576 - val_accuracy: 0.9600\n",
            "Epoch 188/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.1081 - accuracy: 0.9656 - val_loss: 0.1277 - val_accuracy: 0.9733\n",
            "Epoch 189/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0986 - accuracy: 0.9663 - val_loss: 0.1285 - val_accuracy: 0.9733\n",
            "Epoch 190/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0950 - accuracy: 0.9737 - val_loss: 0.1175 - val_accuracy: 0.9767\n",
            "Epoch 191/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0977 - accuracy: 0.9689 - val_loss: 0.1289 - val_accuracy: 0.9667\n",
            "Epoch 192/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0915 - accuracy: 0.9719 - val_loss: 0.1248 - val_accuracy: 0.9733\n",
            "Epoch 193/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0956 - accuracy: 0.9715 - val_loss: 0.1350 - val_accuracy: 0.9700\n",
            "Epoch 194/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0983 - accuracy: 0.9707 - val_loss: 0.1607 - val_accuracy: 0.9633\n",
            "Epoch 195/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0873 - accuracy: 0.9726 - val_loss: 0.1069 - val_accuracy: 0.9767\n",
            "Epoch 196/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.1011 - accuracy: 0.9663 - val_loss: 0.1168 - val_accuracy: 0.9767\n",
            "Epoch 197/1000\n",
            "54/54 [==============================] - 28s 509ms/step - loss: 0.0928 - accuracy: 0.9719 - val_loss: 0.1283 - val_accuracy: 0.9733\n",
            "Epoch 198/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0989 - accuracy: 0.9700 - val_loss: 0.1447 - val_accuracy: 0.9700\n",
            "Epoch 199/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0854 - accuracy: 0.9689 - val_loss: 0.1557 - val_accuracy: 0.9667\n",
            "Epoch 200/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.1034 - accuracy: 0.9641 - val_loss: 0.1358 - val_accuracy: 0.9733\n",
            "Epoch 201/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.1066 - accuracy: 0.9652 - val_loss: 0.1121 - val_accuracy: 0.9733\n",
            "Epoch 202/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0865 - accuracy: 0.9741 - val_loss: 0.1593 - val_accuracy: 0.9667\n",
            "Epoch 203/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0754 - accuracy: 0.9752 - val_loss: 0.1380 - val_accuracy: 0.9733\n",
            "Epoch 204/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0932 - accuracy: 0.9685 - val_loss: 0.1524 - val_accuracy: 0.9667\n",
            "Epoch 205/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0972 - accuracy: 0.9711 - val_loss: 0.1423 - val_accuracy: 0.9733\n",
            "Epoch 206/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0952 - accuracy: 0.9700 - val_loss: 0.1561 - val_accuracy: 0.9600\n",
            "Epoch 207/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0877 - accuracy: 0.9722 - val_loss: 0.1256 - val_accuracy: 0.9733\n",
            "Epoch 208/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0874 - accuracy: 0.9748 - val_loss: 0.1644 - val_accuracy: 0.9600\n",
            "Epoch 209/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.1057 - accuracy: 0.9715 - val_loss: 0.1029 - val_accuracy: 0.9767\n",
            "Epoch 210/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0978 - accuracy: 0.9674 - val_loss: 0.0979 - val_accuracy: 0.9833\n",
            "Epoch 211/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0975 - accuracy: 0.9678 - val_loss: 0.1156 - val_accuracy: 0.9700\n",
            "Epoch 212/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0898 - accuracy: 0.9711 - val_loss: 0.1171 - val_accuracy: 0.9733\n",
            "Epoch 213/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0804 - accuracy: 0.9756 - val_loss: 0.1265 - val_accuracy: 0.9633\n",
            "Epoch 214/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0834 - accuracy: 0.9681 - val_loss: 0.1485 - val_accuracy: 0.9633\n",
            "Epoch 215/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0919 - accuracy: 0.9730 - val_loss: 0.1143 - val_accuracy: 0.9767\n",
            "Epoch 216/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0900 - accuracy: 0.9707 - val_loss: 0.1089 - val_accuracy: 0.9767\n",
            "Epoch 217/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0857 - accuracy: 0.9722 - val_loss: 0.1726 - val_accuracy: 0.9600\n",
            "Epoch 218/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.1004 - accuracy: 0.9730 - val_loss: 0.1202 - val_accuracy: 0.9733\n",
            "Epoch 219/1000\n",
            "54/54 [==============================] - 27s 494ms/step - loss: 0.0806 - accuracy: 0.9763 - val_loss: 0.1289 - val_accuracy: 0.9733\n",
            "Epoch 220/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0757 - accuracy: 0.9796 - val_loss: 0.1837 - val_accuracy: 0.9633\n",
            "Epoch 221/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.1024 - accuracy: 0.9719 - val_loss: 0.1061 - val_accuracy: 0.9767\n",
            "Epoch 222/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0934 - accuracy: 0.9733 - val_loss: 0.1403 - val_accuracy: 0.9633\n",
            "Epoch 223/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0764 - accuracy: 0.9737 - val_loss: 0.1368 - val_accuracy: 0.9733\n",
            "Epoch 224/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0925 - accuracy: 0.9700 - val_loss: 0.1667 - val_accuracy: 0.9667\n",
            "Epoch 225/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0887 - accuracy: 0.9726 - val_loss: 0.1362 - val_accuracy: 0.9633\n",
            "Epoch 226/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0818 - accuracy: 0.9722 - val_loss: 0.1068 - val_accuracy: 0.9800\n",
            "Epoch 227/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.0946 - accuracy: 0.9685 - val_loss: 0.1134 - val_accuracy: 0.9800\n",
            "Epoch 228/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.0735 - accuracy: 0.9741 - val_loss: 0.1504 - val_accuracy: 0.9667\n",
            "Epoch 229/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0841 - accuracy: 0.9741 - val_loss: 0.1229 - val_accuracy: 0.9733\n",
            "Epoch 230/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0796 - accuracy: 0.9770 - val_loss: 0.1504 - val_accuracy: 0.9700\n",
            "Epoch 231/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.0886 - accuracy: 0.9681 - val_loss: 0.1286 - val_accuracy: 0.9733\n",
            "Epoch 232/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0937 - accuracy: 0.9689 - val_loss: 0.1469 - val_accuracy: 0.9600\n",
            "Epoch 233/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.0975 - accuracy: 0.9678 - val_loss: 0.0922 - val_accuracy: 0.9833\n",
            "Epoch 234/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.0876 - accuracy: 0.9730 - val_loss: 0.1074 - val_accuracy: 0.9767\n",
            "Epoch 235/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0909 - accuracy: 0.9741 - val_loss: 0.1182 - val_accuracy: 0.9767\n",
            "Epoch 236/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.0792 - accuracy: 0.9774 - val_loss: 0.1282 - val_accuracy: 0.9733\n",
            "Epoch 237/1000\n",
            "54/54 [==============================] - 26s 473ms/step - loss: 0.0882 - accuracy: 0.9733 - val_loss: 0.0981 - val_accuracy: 0.9867\n",
            "Epoch 238/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.0905 - accuracy: 0.9752 - val_loss: 0.1062 - val_accuracy: 0.9800\n",
            "Epoch 239/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.0858 - accuracy: 0.9700 - val_loss: 0.0936 - val_accuracy: 0.9900\n",
            "Epoch 240/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.0757 - accuracy: 0.9759 - val_loss: 0.0939 - val_accuracy: 0.9900\n",
            "Epoch 241/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0988 - accuracy: 0.9689 - val_loss: 0.1241 - val_accuracy: 0.9800\n",
            "Epoch 242/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0991 - accuracy: 0.9644 - val_loss: 0.1086 - val_accuracy: 0.9800\n",
            "Epoch 243/1000\n",
            "54/54 [==============================] - 26s 473ms/step - loss: 0.0867 - accuracy: 0.9711 - val_loss: 0.1115 - val_accuracy: 0.9800\n",
            "Epoch 244/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.0894 - accuracy: 0.9693 - val_loss: 0.1086 - val_accuracy: 0.9800\n",
            "Epoch 245/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.0808 - accuracy: 0.9741 - val_loss: 0.1090 - val_accuracy: 0.9800\n",
            "Epoch 246/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.0885 - accuracy: 0.9733 - val_loss: 0.1282 - val_accuracy: 0.9767\n",
            "Epoch 247/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0798 - accuracy: 0.9726 - val_loss: 0.1051 - val_accuracy: 0.9833\n",
            "Epoch 248/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.0872 - accuracy: 0.9722 - val_loss: 0.1059 - val_accuracy: 0.9800\n",
            "Epoch 249/1000\n",
            "54/54 [==============================] - 26s 474ms/step - loss: 0.0716 - accuracy: 0.9785 - val_loss: 0.1371 - val_accuracy: 0.9733\n",
            "Epoch 250/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.0851 - accuracy: 0.9730 - val_loss: 0.1133 - val_accuracy: 0.9800\n",
            "Epoch 251/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.0644 - accuracy: 0.9778 - val_loss: 0.1306 - val_accuracy: 0.9767\n",
            "Epoch 252/1000\n",
            "54/54 [==============================] - 26s 475ms/step - loss: 0.0805 - accuracy: 0.9759 - val_loss: 0.1150 - val_accuracy: 0.9767\n",
            "Epoch 253/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.0807 - accuracy: 0.9730 - val_loss: 0.1094 - val_accuracy: 0.9800\n",
            "Epoch 254/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0724 - accuracy: 0.9759 - val_loss: 0.1024 - val_accuracy: 0.9833\n",
            "Epoch 255/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0779 - accuracy: 0.9733 - val_loss: 0.1014 - val_accuracy: 0.9833\n",
            "Epoch 256/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0714 - accuracy: 0.9752 - val_loss: 0.1194 - val_accuracy: 0.9767\n",
            "Epoch 257/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0843 - accuracy: 0.9719 - val_loss: 0.1351 - val_accuracy: 0.9733\n",
            "Epoch 258/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0669 - accuracy: 0.9774 - val_loss: 0.1167 - val_accuracy: 0.9833\n",
            "Epoch 259/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0708 - accuracy: 0.9807 - val_loss: 0.1105 - val_accuracy: 0.9833\n",
            "Epoch 260/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0695 - accuracy: 0.9781 - val_loss: 0.0943 - val_accuracy: 0.9867\n",
            "Epoch 261/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0812 - accuracy: 0.9730 - val_loss: 0.1125 - val_accuracy: 0.9800\n",
            "Epoch 262/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0752 - accuracy: 0.9785 - val_loss: 0.1210 - val_accuracy: 0.9800\n",
            "Epoch 263/1000\n",
            "54/54 [==============================] - 27s 493ms/step - loss: 0.0805 - accuracy: 0.9722 - val_loss: 0.1036 - val_accuracy: 0.9867\n",
            "Epoch 264/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0857 - accuracy: 0.9707 - val_loss: 0.1124 - val_accuracy: 0.9833\n",
            "Epoch 265/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0891 - accuracy: 0.9685 - val_loss: 0.1434 - val_accuracy: 0.9733\n",
            "Epoch 266/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0904 - accuracy: 0.9681 - val_loss: 0.1539 - val_accuracy: 0.9633\n",
            "Epoch 267/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0760 - accuracy: 0.9752 - val_loss: 0.1047 - val_accuracy: 0.9833\n",
            "Epoch 268/1000\n",
            "54/54 [==============================] - 27s 494ms/step - loss: 0.0650 - accuracy: 0.9752 - val_loss: 0.1044 - val_accuracy: 0.9833\n",
            "Epoch 269/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0829 - accuracy: 0.9733 - val_loss: 0.1087 - val_accuracy: 0.9800\n",
            "Epoch 270/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0709 - accuracy: 0.9770 - val_loss: 0.1064 - val_accuracy: 0.9800\n",
            "Epoch 271/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0724 - accuracy: 0.9767 - val_loss: 0.1086 - val_accuracy: 0.9800\n",
            "Epoch 272/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0807 - accuracy: 0.9711 - val_loss: 0.1080 - val_accuracy: 0.9833\n",
            "Epoch 273/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0824 - accuracy: 0.9719 - val_loss: 0.0917 - val_accuracy: 0.9833\n",
            "Epoch 274/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0716 - accuracy: 0.9778 - val_loss: 0.1264 - val_accuracy: 0.9767\n",
            "Epoch 275/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0730 - accuracy: 0.9759 - val_loss: 0.1315 - val_accuracy: 0.9800\n",
            "Epoch 276/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0938 - accuracy: 0.9696 - val_loss: 0.0998 - val_accuracy: 0.9800\n",
            "Epoch 277/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0688 - accuracy: 0.9778 - val_loss: 0.1042 - val_accuracy: 0.9833\n",
            "Epoch 278/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0773 - accuracy: 0.9707 - val_loss: 0.1383 - val_accuracy: 0.9667\n",
            "Epoch 279/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0806 - accuracy: 0.9774 - val_loss: 0.1360 - val_accuracy: 0.9733\n",
            "Epoch 280/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0830 - accuracy: 0.9730 - val_loss: 0.1163 - val_accuracy: 0.9833\n",
            "Epoch 281/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0696 - accuracy: 0.9785 - val_loss: 0.1060 - val_accuracy: 0.9867\n",
            "Epoch 282/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0807 - accuracy: 0.9711 - val_loss: 0.1004 - val_accuracy: 0.9833\n",
            "Epoch 283/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0772 - accuracy: 0.9756 - val_loss: 0.1094 - val_accuracy: 0.9800\n",
            "Epoch 284/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0667 - accuracy: 0.9807 - val_loss: 0.1105 - val_accuracy: 0.9800\n",
            "Epoch 285/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0827 - accuracy: 0.9756 - val_loss: 0.1295 - val_accuracy: 0.9767\n",
            "Epoch 286/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0713 - accuracy: 0.9774 - val_loss: 0.1245 - val_accuracy: 0.9767\n",
            "Epoch 287/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0761 - accuracy: 0.9748 - val_loss: 0.1057 - val_accuracy: 0.9833\n",
            "Epoch 288/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0727 - accuracy: 0.9774 - val_loss: 0.1065 - val_accuracy: 0.9833\n",
            "Epoch 289/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0732 - accuracy: 0.9785 - val_loss: 0.1011 - val_accuracy: 0.9833\n",
            "Epoch 290/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0773 - accuracy: 0.9733 - val_loss: 0.1236 - val_accuracy: 0.9767\n",
            "Epoch 291/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0851 - accuracy: 0.9719 - val_loss: 0.0980 - val_accuracy: 0.9867\n",
            "Epoch 292/1000\n",
            "54/54 [==============================] - 28s 524ms/step - loss: 0.0753 - accuracy: 0.9752 - val_loss: 0.1044 - val_accuracy: 0.9767\n",
            "Epoch 293/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0767 - accuracy: 0.9756 - val_loss: 0.1140 - val_accuracy: 0.9833\n",
            "Epoch 294/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0643 - accuracy: 0.9796 - val_loss: 0.1409 - val_accuracy: 0.9767\n",
            "Epoch 295/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0868 - accuracy: 0.9700 - val_loss: 0.1137 - val_accuracy: 0.9800\n",
            "Epoch 296/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0620 - accuracy: 0.9800 - val_loss: 0.1488 - val_accuracy: 0.9767\n",
            "Epoch 297/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0752 - accuracy: 0.9796 - val_loss: 0.1490 - val_accuracy: 0.9733\n",
            "Epoch 298/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0646 - accuracy: 0.9789 - val_loss: 0.1246 - val_accuracy: 0.9800\n",
            "Epoch 299/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0700 - accuracy: 0.9759 - val_loss: 0.1489 - val_accuracy: 0.9700\n",
            "Epoch 300/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0628 - accuracy: 0.9778 - val_loss: 0.1096 - val_accuracy: 0.9733\n",
            "Epoch 301/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0663 - accuracy: 0.9789 - val_loss: 0.1056 - val_accuracy: 0.9800\n",
            "Epoch 302/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0760 - accuracy: 0.9759 - val_loss: 0.1232 - val_accuracy: 0.9767\n",
            "Epoch 303/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0743 - accuracy: 0.9752 - val_loss: 0.1077 - val_accuracy: 0.9867\n",
            "Epoch 304/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0771 - accuracy: 0.9748 - val_loss: 0.1027 - val_accuracy: 0.9833\n",
            "Epoch 305/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0664 - accuracy: 0.9778 - val_loss: 0.1059 - val_accuracy: 0.9833\n",
            "Epoch 306/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0570 - accuracy: 0.9826 - val_loss: 0.1006 - val_accuracy: 0.9867\n",
            "Epoch 307/1000\n",
            "54/54 [==============================] - 26s 490ms/step - loss: 0.0530 - accuracy: 0.9819 - val_loss: 0.0993 - val_accuracy: 0.9867\n",
            "Epoch 308/1000\n",
            "54/54 [==============================] - 27s 491ms/step - loss: 0.0789 - accuracy: 0.9763 - val_loss: 0.1060 - val_accuracy: 0.9833\n",
            "Epoch 309/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0739 - accuracy: 0.9733 - val_loss: 0.0967 - val_accuracy: 0.9867\n",
            "Epoch 310/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0783 - accuracy: 0.9767 - val_loss: 0.1181 - val_accuracy: 0.9733\n",
            "Epoch 311/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0633 - accuracy: 0.9815 - val_loss: 0.1208 - val_accuracy: 0.9733\n",
            "Epoch 312/1000\n",
            "54/54 [==============================] - 28s 509ms/step - loss: 0.0695 - accuracy: 0.9759 - val_loss: 0.0963 - val_accuracy: 0.9800\n",
            "Epoch 313/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0654 - accuracy: 0.9789 - val_loss: 0.1063 - val_accuracy: 0.9800\n",
            "Epoch 314/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0734 - accuracy: 0.9767 - val_loss: 0.1064 - val_accuracy: 0.9800\n",
            "Epoch 315/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0707 - accuracy: 0.9774 - val_loss: 0.1102 - val_accuracy: 0.9767\n",
            "Epoch 316/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0727 - accuracy: 0.9767 - val_loss: 0.1208 - val_accuracy: 0.9800\n",
            "Epoch 317/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0749 - accuracy: 0.9726 - val_loss: 0.1244 - val_accuracy: 0.9733\n",
            "Epoch 318/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0722 - accuracy: 0.9737 - val_loss: 0.1028 - val_accuracy: 0.9733\n",
            "Epoch 319/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0708 - accuracy: 0.9785 - val_loss: 0.1076 - val_accuracy: 0.9767\n",
            "Epoch 320/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0700 - accuracy: 0.9770 - val_loss: 0.1017 - val_accuracy: 0.9767\n",
            "Epoch 321/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0776 - accuracy: 0.9770 - val_loss: 0.1180 - val_accuracy: 0.9733\n",
            "Epoch 322/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0705 - accuracy: 0.9759 - val_loss: 0.1156 - val_accuracy: 0.9733\n",
            "Epoch 323/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0690 - accuracy: 0.9811 - val_loss: 0.1252 - val_accuracy: 0.9800\n",
            "Epoch 324/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0618 - accuracy: 0.9804 - val_loss: 0.1199 - val_accuracy: 0.9733\n",
            "Epoch 325/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0708 - accuracy: 0.9756 - val_loss: 0.0999 - val_accuracy: 0.9800\n",
            "Epoch 326/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0601 - accuracy: 0.9819 - val_loss: 0.1218 - val_accuracy: 0.9800\n",
            "Epoch 327/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0671 - accuracy: 0.9785 - val_loss: 0.1103 - val_accuracy: 0.9733\n",
            "Epoch 328/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0693 - accuracy: 0.9789 - val_loss: 0.1089 - val_accuracy: 0.9767\n",
            "Epoch 329/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0658 - accuracy: 0.9785 - val_loss: 0.1064 - val_accuracy: 0.9800\n",
            "Epoch 330/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0629 - accuracy: 0.9796 - val_loss: 0.1292 - val_accuracy: 0.9767\n",
            "Epoch 331/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0594 - accuracy: 0.9811 - val_loss: 0.1172 - val_accuracy: 0.9800\n",
            "Epoch 332/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0646 - accuracy: 0.9807 - val_loss: 0.0970 - val_accuracy: 0.9833\n",
            "Epoch 333/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0567 - accuracy: 0.9815 - val_loss: 0.1112 - val_accuracy: 0.9767\n",
            "Epoch 334/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0615 - accuracy: 0.9811 - val_loss: 0.1515 - val_accuracy: 0.9667\n",
            "Epoch 335/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0857 - accuracy: 0.9756 - val_loss: 0.1090 - val_accuracy: 0.9767\n",
            "Epoch 336/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0656 - accuracy: 0.9719 - val_loss: 0.1250 - val_accuracy: 0.9700\n",
            "Epoch 337/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0665 - accuracy: 0.9774 - val_loss: 0.1005 - val_accuracy: 0.9800\n",
            "Epoch 338/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0598 - accuracy: 0.9804 - val_loss: 0.1055 - val_accuracy: 0.9833\n",
            "Epoch 339/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0788 - accuracy: 0.9741 - val_loss: 0.1380 - val_accuracy: 0.9700\n",
            "Epoch 340/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0611 - accuracy: 0.9778 - val_loss: 0.1329 - val_accuracy: 0.9733\n",
            "Epoch 341/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0666 - accuracy: 0.9796 - val_loss: 0.1104 - val_accuracy: 0.9733\n",
            "Epoch 342/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0527 - accuracy: 0.9863 - val_loss: 0.1506 - val_accuracy: 0.9667\n",
            "Epoch 343/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0597 - accuracy: 0.9800 - val_loss: 0.1498 - val_accuracy: 0.9667\n",
            "Epoch 344/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0758 - accuracy: 0.9774 - val_loss: 0.0877 - val_accuracy: 0.9900\n",
            "Epoch 345/1000\n",
            "54/54 [==============================] - 27s 494ms/step - loss: 0.0659 - accuracy: 0.9770 - val_loss: 0.1073 - val_accuracy: 0.9767\n",
            "Epoch 346/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0689 - accuracy: 0.9796 - val_loss: 0.1230 - val_accuracy: 0.9767\n",
            "Epoch 347/1000\n",
            "54/54 [==============================] - 27s 493ms/step - loss: 0.0698 - accuracy: 0.9800 - val_loss: 0.1350 - val_accuracy: 0.9667\n",
            "Epoch 348/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0614 - accuracy: 0.9811 - val_loss: 0.1025 - val_accuracy: 0.9833\n",
            "Epoch 349/1000\n",
            "54/54 [==============================] - 27s 493ms/step - loss: 0.0777 - accuracy: 0.9770 - val_loss: 0.1510 - val_accuracy: 0.9700\n",
            "Epoch 350/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0798 - accuracy: 0.9763 - val_loss: 0.1270 - val_accuracy: 0.9733\n",
            "Epoch 351/1000\n",
            "54/54 [==============================] - 26s 490ms/step - loss: 0.0707 - accuracy: 0.9793 - val_loss: 0.1024 - val_accuracy: 0.9767\n",
            "Epoch 352/1000\n",
            "54/54 [==============================] - 27s 491ms/step - loss: 0.0604 - accuracy: 0.9793 - val_loss: 0.1439 - val_accuracy: 0.9700\n",
            "Epoch 353/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0629 - accuracy: 0.9781 - val_loss: 0.0943 - val_accuracy: 0.9867\n",
            "Epoch 354/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0766 - accuracy: 0.9774 - val_loss: 0.1020 - val_accuracy: 0.9800\n",
            "Epoch 355/1000\n",
            "54/54 [==============================] - 27s 493ms/step - loss: 0.0616 - accuracy: 0.9804 - val_loss: 0.1440 - val_accuracy: 0.9700\n",
            "Epoch 356/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0733 - accuracy: 0.9756 - val_loss: 0.1384 - val_accuracy: 0.9700\n",
            "Epoch 357/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0527 - accuracy: 0.9833 - val_loss: 0.1161 - val_accuracy: 0.9767\n",
            "Epoch 358/1000\n",
            "54/54 [==============================] - 26s 490ms/step - loss: 0.0749 - accuracy: 0.9744 - val_loss: 0.1053 - val_accuracy: 0.9833\n",
            "Epoch 359/1000\n",
            "54/54 [==============================] - 27s 493ms/step - loss: 0.0569 - accuracy: 0.9804 - val_loss: 0.1354 - val_accuracy: 0.9767\n",
            "Epoch 360/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0654 - accuracy: 0.9800 - val_loss: 0.1087 - val_accuracy: 0.9767\n",
            "Epoch 361/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0715 - accuracy: 0.9759 - val_loss: 0.1078 - val_accuracy: 0.9800\n",
            "Epoch 362/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0544 - accuracy: 0.9830 - val_loss: 0.1034 - val_accuracy: 0.9800\n",
            "Epoch 363/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0691 - accuracy: 0.9752 - val_loss: 0.1659 - val_accuracy: 0.9700\n",
            "Epoch 364/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 0.1015 - val_accuracy: 0.9833\n",
            "Epoch 365/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0686 - accuracy: 0.9785 - val_loss: 0.1209 - val_accuracy: 0.9767\n",
            "Epoch 366/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0746 - accuracy: 0.9781 - val_loss: 0.1006 - val_accuracy: 0.9800\n",
            "Epoch 367/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0762 - accuracy: 0.9785 - val_loss: 0.1443 - val_accuracy: 0.9667\n",
            "Epoch 368/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0540 - accuracy: 0.9822 - val_loss: 0.1257 - val_accuracy: 0.9733\n",
            "Epoch 369/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0666 - accuracy: 0.9793 - val_loss: 0.0845 - val_accuracy: 0.9867\n",
            "Epoch 370/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0734 - accuracy: 0.9752 - val_loss: 0.0966 - val_accuracy: 0.9867\n",
            "Epoch 371/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0537 - accuracy: 0.9822 - val_loss: 0.1106 - val_accuracy: 0.9833\n",
            "Epoch 372/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0646 - accuracy: 0.9770 - val_loss: 0.0945 - val_accuracy: 0.9867\n",
            "Epoch 373/1000\n",
            "54/54 [==============================] - 27s 491ms/step - loss: 0.0663 - accuracy: 0.9793 - val_loss: 0.1152 - val_accuracy: 0.9833\n",
            "Epoch 374/1000\n",
            "54/54 [==============================] - 27s 493ms/step - loss: 0.0514 - accuracy: 0.9837 - val_loss: 0.1242 - val_accuracy: 0.9800\n",
            "Epoch 375/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0639 - accuracy: 0.9804 - val_loss: 0.1112 - val_accuracy: 0.9833\n",
            "Epoch 376/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0549 - accuracy: 0.9793 - val_loss: 0.1171 - val_accuracy: 0.9833\n",
            "Epoch 377/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0651 - accuracy: 0.9830 - val_loss: 0.1128 - val_accuracy: 0.9833\n",
            "Epoch 378/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0675 - accuracy: 0.9759 - val_loss: 0.0922 - val_accuracy: 0.9867\n",
            "Epoch 379/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0679 - accuracy: 0.9774 - val_loss: 0.0870 - val_accuracy: 0.9867\n",
            "Epoch 380/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0630 - accuracy: 0.9796 - val_loss: 0.0976 - val_accuracy: 0.9833\n",
            "Epoch 381/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0545 - accuracy: 0.9815 - val_loss: 0.0930 - val_accuracy: 0.9867\n",
            "Epoch 382/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0705 - accuracy: 0.9763 - val_loss: 0.1255 - val_accuracy: 0.9767\n",
            "Epoch 383/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0543 - accuracy: 0.9819 - val_loss: 0.1347 - val_accuracy: 0.9733\n",
            "Epoch 384/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0521 - accuracy: 0.9822 - val_loss: 0.1257 - val_accuracy: 0.9800\n",
            "Epoch 385/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0565 - accuracy: 0.9837 - val_loss: 0.1180 - val_accuracy: 0.9800\n",
            "Epoch 386/1000\n",
            "54/54 [==============================] - 27s 491ms/step - loss: 0.0650 - accuracy: 0.9789 - val_loss: 0.1031 - val_accuracy: 0.9800\n",
            "Epoch 387/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0676 - accuracy: 0.9778 - val_loss: 0.1005 - val_accuracy: 0.9833\n",
            "Epoch 388/1000\n",
            "54/54 [==============================] - 26s 490ms/step - loss: 0.0627 - accuracy: 0.9781 - val_loss: 0.1095 - val_accuracy: 0.9767\n",
            "Epoch 389/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0666 - accuracy: 0.9778 - val_loss: 0.1248 - val_accuracy: 0.9733\n",
            "Epoch 390/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0614 - accuracy: 0.9781 - val_loss: 0.1009 - val_accuracy: 0.9833\n",
            "Epoch 391/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0528 - accuracy: 0.9804 - val_loss: 0.1050 - val_accuracy: 0.9800\n",
            "Epoch 392/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0632 - accuracy: 0.9789 - val_loss: 0.0964 - val_accuracy: 0.9833\n",
            "Epoch 393/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0578 - accuracy: 0.9819 - val_loss: 0.1343 - val_accuracy: 0.9700\n",
            "Epoch 394/1000\n",
            "54/54 [==============================] - 27s 495ms/step - loss: 0.0620 - accuracy: 0.9807 - val_loss: 0.1086 - val_accuracy: 0.9867\n",
            "Epoch 395/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0761 - accuracy: 0.9763 - val_loss: 0.1126 - val_accuracy: 0.9767\n",
            "Epoch 396/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0643 - accuracy: 0.9811 - val_loss: 0.1412 - val_accuracy: 0.9733\n",
            "Epoch 397/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0560 - accuracy: 0.9833 - val_loss: 0.1399 - val_accuracy: 0.9667\n",
            "Epoch 398/1000\n",
            "54/54 [==============================] - 26s 490ms/step - loss: 0.0661 - accuracy: 0.9785 - val_loss: 0.0936 - val_accuracy: 0.9900\n",
            "Epoch 399/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0665 - accuracy: 0.9763 - val_loss: 0.0915 - val_accuracy: 0.9867\n",
            "Epoch 400/1000\n",
            "54/54 [==============================] - 26s 490ms/step - loss: 0.0505 - accuracy: 0.9833 - val_loss: 0.0865 - val_accuracy: 0.9867\n",
            "Epoch 401/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0622 - accuracy: 0.9793 - val_loss: 0.0989 - val_accuracy: 0.9833\n",
            "Epoch 402/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0639 - accuracy: 0.9815 - val_loss: 0.1130 - val_accuracy: 0.9833\n",
            "Epoch 403/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0635 - accuracy: 0.9826 - val_loss: 0.1313 - val_accuracy: 0.9733\n",
            "Epoch 404/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0668 - accuracy: 0.9781 - val_loss: 0.0978 - val_accuracy: 0.9867\n",
            "Epoch 405/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0654 - accuracy: 0.9781 - val_loss: 0.1452 - val_accuracy: 0.9667\n",
            "Epoch 406/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0679 - accuracy: 0.9763 - val_loss: 0.0980 - val_accuracy: 0.9833\n",
            "Epoch 407/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0552 - accuracy: 0.9804 - val_loss: 0.0828 - val_accuracy: 0.9867\n",
            "Epoch 408/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0612 - accuracy: 0.9796 - val_loss: 0.1059 - val_accuracy: 0.9800\n",
            "Epoch 409/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0531 - accuracy: 0.9833 - val_loss: 0.0959 - val_accuracy: 0.9833\n",
            "Epoch 410/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0637 - accuracy: 0.9800 - val_loss: 0.1080 - val_accuracy: 0.9800\n",
            "Epoch 411/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0581 - accuracy: 0.9826 - val_loss: 0.1029 - val_accuracy: 0.9800\n",
            "Epoch 412/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0650 - accuracy: 0.9833 - val_loss: 0.1359 - val_accuracy: 0.9700\n",
            "Epoch 413/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0642 - accuracy: 0.9793 - val_loss: 0.1315 - val_accuracy: 0.9767\n",
            "Epoch 414/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0552 - accuracy: 0.9822 - val_loss: 0.1465 - val_accuracy: 0.9700\n",
            "Epoch 415/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0603 - accuracy: 0.9785 - val_loss: 0.1032 - val_accuracy: 0.9833\n",
            "Epoch 416/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0619 - accuracy: 0.9811 - val_loss: 0.0804 - val_accuracy: 0.9867\n",
            "Epoch 417/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0594 - accuracy: 0.9822 - val_loss: 0.1056 - val_accuracy: 0.9833\n",
            "Epoch 418/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0644 - accuracy: 0.9796 - val_loss: 0.0858 - val_accuracy: 0.9900\n",
            "Epoch 419/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0498 - accuracy: 0.9815 - val_loss: 0.1200 - val_accuracy: 0.9767\n",
            "Epoch 420/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0549 - accuracy: 0.9815 - val_loss: 0.1073 - val_accuracy: 0.9867\n",
            "Epoch 421/1000\n",
            "54/54 [==============================] - 27s 495ms/step - loss: 0.0602 - accuracy: 0.9819 - val_loss: 0.1284 - val_accuracy: 0.9767\n",
            "Epoch 422/1000\n",
            "54/54 [==============================] - 27s 491ms/step - loss: 0.0600 - accuracy: 0.9807 - val_loss: 0.1129 - val_accuracy: 0.9767\n",
            "Epoch 423/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0734 - accuracy: 0.9796 - val_loss: 0.1062 - val_accuracy: 0.9867\n",
            "Epoch 424/1000\n",
            "54/54 [==============================] - 26s 490ms/step - loss: 0.0577 - accuracy: 0.9833 - val_loss: 0.1397 - val_accuracy: 0.9733\n",
            "Epoch 425/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0576 - accuracy: 0.9819 - val_loss: 0.1362 - val_accuracy: 0.9700\n",
            "Epoch 426/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0448 - accuracy: 0.9852 - val_loss: 0.1586 - val_accuracy: 0.9700\n",
            "Epoch 427/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0480 - accuracy: 0.9811 - val_loss: 0.0974 - val_accuracy: 0.9833\n",
            "Epoch 428/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0596 - accuracy: 0.9815 - val_loss: 0.1140 - val_accuracy: 0.9833\n",
            "Epoch 429/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0564 - accuracy: 0.9819 - val_loss: 0.0854 - val_accuracy: 0.9900\n",
            "Epoch 430/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0548 - accuracy: 0.9815 - val_loss: 0.1137 - val_accuracy: 0.9800\n",
            "Epoch 431/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0481 - accuracy: 0.9878 - val_loss: 0.0986 - val_accuracy: 0.9833\n",
            "Epoch 432/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0623 - accuracy: 0.9778 - val_loss: 0.1110 - val_accuracy: 0.9833\n",
            "Epoch 433/1000\n",
            "54/54 [==============================] - 27s 493ms/step - loss: 0.0411 - accuracy: 0.9863 - val_loss: 0.1370 - val_accuracy: 0.9767\n",
            "Epoch 434/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0547 - accuracy: 0.9833 - val_loss: 0.1096 - val_accuracy: 0.9800\n",
            "Epoch 435/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0596 - accuracy: 0.9796 - val_loss: 0.0922 - val_accuracy: 0.9833\n",
            "Epoch 436/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0561 - accuracy: 0.9844 - val_loss: 0.1098 - val_accuracy: 0.9833\n",
            "Epoch 437/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0678 - accuracy: 0.9756 - val_loss: 0.0914 - val_accuracy: 0.9900\n",
            "Epoch 438/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0580 - accuracy: 0.9789 - val_loss: 0.1398 - val_accuracy: 0.9700\n",
            "Epoch 439/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0767 - accuracy: 0.9767 - val_loss: 0.0915 - val_accuracy: 0.9833\n",
            "Epoch 440/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0492 - accuracy: 0.9859 - val_loss: 0.1166 - val_accuracy: 0.9800\n",
            "Epoch 441/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0521 - accuracy: 0.9830 - val_loss: 0.1144 - val_accuracy: 0.9800\n",
            "Epoch 442/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0455 - accuracy: 0.9867 - val_loss: 0.0741 - val_accuracy: 0.9900\n",
            "Epoch 443/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0569 - accuracy: 0.9789 - val_loss: 0.0702 - val_accuracy: 0.9867\n",
            "Epoch 444/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0549 - accuracy: 0.9822 - val_loss: 0.1108 - val_accuracy: 0.9800\n",
            "Epoch 445/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0589 - accuracy: 0.9804 - val_loss: 0.0949 - val_accuracy: 0.9800\n",
            "Epoch 446/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0503 - accuracy: 0.9874 - val_loss: 0.1285 - val_accuracy: 0.9767\n",
            "Epoch 447/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0475 - accuracy: 0.9848 - val_loss: 0.1034 - val_accuracy: 0.9767\n",
            "Epoch 448/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0604 - accuracy: 0.9804 - val_loss: 0.0920 - val_accuracy: 0.9867\n",
            "Epoch 449/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0650 - accuracy: 0.9744 - val_loss: 0.0937 - val_accuracy: 0.9833\n",
            "Epoch 450/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0445 - accuracy: 0.9881 - val_loss: 0.1076 - val_accuracy: 0.9800\n",
            "Epoch 451/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.1341 - val_accuracy: 0.9800\n",
            "Epoch 452/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0743 - accuracy: 0.9774 - val_loss: 0.1154 - val_accuracy: 0.9833\n",
            "Epoch 453/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0418 - accuracy: 0.9852 - val_loss: 0.1154 - val_accuracy: 0.9833\n",
            "Epoch 454/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0445 - accuracy: 0.9841 - val_loss: 0.1121 - val_accuracy: 0.9800\n",
            "Epoch 455/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0667 - accuracy: 0.9811 - val_loss: 0.1061 - val_accuracy: 0.9833\n",
            "Epoch 456/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0622 - accuracy: 0.9781 - val_loss: 0.0768 - val_accuracy: 0.9833\n",
            "Epoch 457/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0526 - accuracy: 0.9819 - val_loss: 0.0960 - val_accuracy: 0.9800\n",
            "Epoch 458/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0563 - accuracy: 0.9822 - val_loss: 0.1112 - val_accuracy: 0.9767\n",
            "Epoch 459/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0582 - accuracy: 0.9815 - val_loss: 0.1100 - val_accuracy: 0.9800\n",
            "Epoch 460/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0568 - accuracy: 0.9811 - val_loss: 0.1151 - val_accuracy: 0.9767\n",
            "Epoch 461/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0582 - accuracy: 0.9852 - val_loss: 0.1033 - val_accuracy: 0.9800\n",
            "Epoch 462/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0567 - accuracy: 0.9826 - val_loss: 0.1312 - val_accuracy: 0.9733\n",
            "Epoch 463/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0580 - accuracy: 0.9815 - val_loss: 0.1159 - val_accuracy: 0.9733\n",
            "Epoch 464/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0568 - accuracy: 0.9807 - val_loss: 0.0867 - val_accuracy: 0.9800\n",
            "Epoch 465/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0500 - accuracy: 0.9804 - val_loss: 0.1285 - val_accuracy: 0.9767\n",
            "Epoch 466/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0551 - accuracy: 0.9793 - val_loss: 0.1085 - val_accuracy: 0.9767\n",
            "Epoch 467/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0496 - accuracy: 0.9867 - val_loss: 0.1197 - val_accuracy: 0.9767\n",
            "Epoch 468/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0634 - accuracy: 0.9756 - val_loss: 0.0939 - val_accuracy: 0.9800\n",
            "Epoch 469/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0596 - accuracy: 0.9793 - val_loss: 0.1031 - val_accuracy: 0.9800\n",
            "Epoch 470/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0545 - accuracy: 0.9822 - val_loss: 0.0933 - val_accuracy: 0.9867\n",
            "Epoch 471/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0525 - accuracy: 0.9848 - val_loss: 0.1338 - val_accuracy: 0.9733\n",
            "Epoch 472/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0496 - accuracy: 0.9867 - val_loss: 0.0865 - val_accuracy: 0.9900\n",
            "Epoch 473/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0553 - accuracy: 0.9811 - val_loss: 0.0851 - val_accuracy: 0.9900\n",
            "Epoch 474/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0623 - accuracy: 0.9800 - val_loss: 0.0859 - val_accuracy: 0.9867\n",
            "Epoch 475/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0583 - accuracy: 0.9819 - val_loss: 0.1051 - val_accuracy: 0.9767\n",
            "Epoch 476/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0508 - accuracy: 0.9841 - val_loss: 0.1144 - val_accuracy: 0.9767\n",
            "Epoch 477/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0498 - accuracy: 0.9830 - val_loss: 0.0888 - val_accuracy: 0.9900\n",
            "Epoch 478/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0498 - accuracy: 0.9815 - val_loss: 0.0974 - val_accuracy: 0.9867\n",
            "Epoch 479/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0520 - accuracy: 0.9837 - val_loss: 0.0980 - val_accuracy: 0.9867\n",
            "Epoch 480/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0609 - accuracy: 0.9796 - val_loss: 0.1016 - val_accuracy: 0.9833\n",
            "Epoch 481/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0502 - accuracy: 0.9826 - val_loss: 0.1012 - val_accuracy: 0.9833\n",
            "Epoch 482/1000\n",
            "54/54 [==============================] - 27s 491ms/step - loss: 0.0543 - accuracy: 0.9841 - val_loss: 0.0934 - val_accuracy: 0.9833\n",
            "Epoch 483/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0573 - accuracy: 0.9830 - val_loss: 0.0839 - val_accuracy: 0.9833\n",
            "Epoch 484/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0464 - accuracy: 0.9859 - val_loss: 0.1094 - val_accuracy: 0.9800\n",
            "Epoch 485/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0604 - accuracy: 0.9856 - val_loss: 0.0990 - val_accuracy: 0.9833\n",
            "Epoch 486/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0407 - accuracy: 0.9874 - val_loss: 0.0812 - val_accuracy: 0.9867\n",
            "Epoch 487/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0487 - accuracy: 0.9822 - val_loss: 0.0932 - val_accuracy: 0.9867\n",
            "Epoch 488/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0475 - accuracy: 0.9848 - val_loss: 0.0919 - val_accuracy: 0.9833\n",
            "Epoch 489/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0536 - accuracy: 0.9804 - val_loss: 0.1087 - val_accuracy: 0.9767\n",
            "Epoch 490/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0505 - accuracy: 0.9837 - val_loss: 0.0865 - val_accuracy: 0.9867\n",
            "Epoch 491/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0558 - accuracy: 0.9826 - val_loss: 0.0943 - val_accuracy: 0.9800\n",
            "Epoch 492/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0558 - accuracy: 0.9785 - val_loss: 0.0971 - val_accuracy: 0.9833\n",
            "Epoch 493/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0577 - accuracy: 0.9833 - val_loss: 0.1060 - val_accuracy: 0.9833\n",
            "Epoch 494/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0553 - accuracy: 0.9830 - val_loss: 0.0915 - val_accuracy: 0.9867\n",
            "Epoch 495/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0500 - accuracy: 0.9811 - val_loss: 0.1075 - val_accuracy: 0.9800\n",
            "Epoch 496/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0600 - accuracy: 0.9800 - val_loss: 0.1106 - val_accuracy: 0.9767\n",
            "Epoch 497/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 0.1085 - val_accuracy: 0.9767\n",
            "Epoch 498/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0617 - accuracy: 0.9796 - val_loss: 0.1144 - val_accuracy: 0.9833\n",
            "Epoch 499/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0475 - accuracy: 0.9830 - val_loss: 0.1104 - val_accuracy: 0.9733\n",
            "Epoch 500/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0480 - accuracy: 0.9844 - val_loss: 0.0864 - val_accuracy: 0.9867\n",
            "Epoch 501/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0615 - accuracy: 0.9774 - val_loss: 0.0876 - val_accuracy: 0.9867\n",
            "Epoch 502/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0601 - accuracy: 0.9789 - val_loss: 0.1244 - val_accuracy: 0.9800\n",
            "Epoch 503/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.1038 - val_accuracy: 0.9867\n",
            "Epoch 504/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0502 - accuracy: 0.9837 - val_loss: 0.1045 - val_accuracy: 0.9833\n",
            "Epoch 505/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0457 - accuracy: 0.9870 - val_loss: 0.1001 - val_accuracy: 0.9800\n",
            "Epoch 506/1000\n",
            "54/54 [==============================] - 28s 509ms/step - loss: 0.0456 - accuracy: 0.9859 - val_loss: 0.1198 - val_accuracy: 0.9800\n",
            "Epoch 507/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0583 - accuracy: 0.9807 - val_loss: 0.0869 - val_accuracy: 0.9833\n",
            "Epoch 508/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0458 - accuracy: 0.9856 - val_loss: 0.0927 - val_accuracy: 0.9867\n",
            "Epoch 509/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.1184 - val_accuracy: 0.9800\n",
            "Epoch 510/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0433 - accuracy: 0.9863 - val_loss: 0.0952 - val_accuracy: 0.9867\n",
            "Epoch 511/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0494 - accuracy: 0.9830 - val_loss: 0.0848 - val_accuracy: 0.9867\n",
            "Epoch 512/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0445 - accuracy: 0.9826 - val_loss: 0.0980 - val_accuracy: 0.9800\n",
            "Epoch 513/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0667 - accuracy: 0.9774 - val_loss: 0.0864 - val_accuracy: 0.9867\n",
            "Epoch 514/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0435 - accuracy: 0.9841 - val_loss: 0.0948 - val_accuracy: 0.9867\n",
            "Epoch 515/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0457 - accuracy: 0.9870 - val_loss: 0.0861 - val_accuracy: 0.9867\n",
            "Epoch 516/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0410 - accuracy: 0.9878 - val_loss: 0.1081 - val_accuracy: 0.9833\n",
            "Epoch 517/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0594 - accuracy: 0.9826 - val_loss: 0.1045 - val_accuracy: 0.9800\n",
            "Epoch 518/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0469 - accuracy: 0.9815 - val_loss: 0.0867 - val_accuracy: 0.9867\n",
            "Epoch 519/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0478 - accuracy: 0.9815 - val_loss: 0.0880 - val_accuracy: 0.9867\n",
            "Epoch 520/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0507 - accuracy: 0.9822 - val_loss: 0.0947 - val_accuracy: 0.9867\n",
            "Epoch 521/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0518 - accuracy: 0.9848 - val_loss: 0.1092 - val_accuracy: 0.9867\n",
            "Epoch 522/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0500 - accuracy: 0.9804 - val_loss: 0.1110 - val_accuracy: 0.9800\n",
            "Epoch 523/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0486 - accuracy: 0.9867 - val_loss: 0.1030 - val_accuracy: 0.9800\n",
            "Epoch 524/1000\n",
            "54/54 [==============================] - 28s 528ms/step - loss: 0.0609 - accuracy: 0.9815 - val_loss: 0.0650 - val_accuracy: 0.9900\n",
            "Epoch 525/1000\n",
            "54/54 [==============================] - 28s 523ms/step - loss: 0.0525 - accuracy: 0.9841 - val_loss: 0.0958 - val_accuracy: 0.9833\n",
            "Epoch 526/1000\n",
            "54/54 [==============================] - 28s 524ms/step - loss: 0.0465 - accuracy: 0.9837 - val_loss: 0.0759 - val_accuracy: 0.9900\n",
            "Epoch 527/1000\n",
            "54/54 [==============================] - 28s 520ms/step - loss: 0.0692 - accuracy: 0.9748 - val_loss: 0.0961 - val_accuracy: 0.9867\n",
            "Epoch 528/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0480 - accuracy: 0.9815 - val_loss: 0.1154 - val_accuracy: 0.9800\n",
            "Epoch 529/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0545 - accuracy: 0.9822 - val_loss: 0.1022 - val_accuracy: 0.9867\n",
            "Epoch 530/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.0952 - val_accuracy: 0.9867\n",
            "Epoch 531/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0581 - accuracy: 0.9807 - val_loss: 0.0817 - val_accuracy: 0.9900\n",
            "Epoch 532/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0384 - accuracy: 0.9848 - val_loss: 0.1009 - val_accuracy: 0.9833\n",
            "Epoch 533/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0566 - accuracy: 0.9830 - val_loss: 0.0717 - val_accuracy: 0.9833\n",
            "Epoch 534/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.0742 - val_accuracy: 0.9867\n",
            "Epoch 535/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0417 - accuracy: 0.9848 - val_loss: 0.1026 - val_accuracy: 0.9867\n",
            "Epoch 536/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.0952 - val_accuracy: 0.9867\n",
            "Epoch 537/1000\n",
            "54/54 [==============================] - 28s 520ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.0659 - val_accuracy: 0.9900\n",
            "Epoch 538/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0523 - accuracy: 0.9848 - val_loss: 0.0740 - val_accuracy: 0.9900\n",
            "Epoch 539/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0540 - accuracy: 0.9826 - val_loss: 0.0701 - val_accuracy: 0.9900\n",
            "Epoch 540/1000\n",
            "54/54 [==============================] - 28s 522ms/step - loss: 0.0477 - accuracy: 0.9844 - val_loss: 0.0868 - val_accuracy: 0.9800\n",
            "Epoch 541/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0500 - accuracy: 0.9867 - val_loss: 0.0913 - val_accuracy: 0.9900\n",
            "Epoch 542/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0484 - accuracy: 0.9867 - val_loss: 0.0940 - val_accuracy: 0.9867\n",
            "Epoch 543/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0421 - accuracy: 0.9844 - val_loss: 0.0944 - val_accuracy: 0.9833\n",
            "Epoch 544/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0418 - accuracy: 0.9874 - val_loss: 0.0848 - val_accuracy: 0.9833\n",
            "Epoch 545/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0444 - accuracy: 0.9874 - val_loss: 0.0769 - val_accuracy: 0.9900\n",
            "Epoch 546/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0491 - accuracy: 0.9837 - val_loss: 0.0970 - val_accuracy: 0.9867\n",
            "Epoch 547/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 0.1040 - val_accuracy: 0.9833\n",
            "Epoch 548/1000\n",
            "54/54 [==============================] - 28s 523ms/step - loss: 0.0550 - accuracy: 0.9822 - val_loss: 0.1369 - val_accuracy: 0.9733\n",
            "Epoch 549/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0486 - accuracy: 0.9848 - val_loss: 0.0933 - val_accuracy: 0.9867\n",
            "Epoch 550/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0479 - accuracy: 0.9841 - val_loss: 0.1165 - val_accuracy: 0.9833\n",
            "Epoch 551/1000\n",
            "54/54 [==============================] - 28s 524ms/step - loss: 0.0415 - accuracy: 0.9856 - val_loss: 0.1277 - val_accuracy: 0.9833\n",
            "Epoch 552/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0431 - accuracy: 0.9848 - val_loss: 0.0987 - val_accuracy: 0.9867\n",
            "Epoch 553/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0485 - accuracy: 0.9856 - val_loss: 0.1013 - val_accuracy: 0.9867\n",
            "Epoch 554/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0554 - accuracy: 0.9848 - val_loss: 0.1137 - val_accuracy: 0.9833\n",
            "Epoch 555/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0494 - accuracy: 0.9833 - val_loss: 0.1010 - val_accuracy: 0.9900\n",
            "Epoch 556/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0435 - accuracy: 0.9848 - val_loss: 0.1074 - val_accuracy: 0.9867\n",
            "Epoch 557/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0561 - accuracy: 0.9811 - val_loss: 0.1033 - val_accuracy: 0.9833\n",
            "Epoch 558/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0440 - accuracy: 0.9830 - val_loss: 0.1074 - val_accuracy: 0.9767\n",
            "Epoch 559/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.0874 - val_accuracy: 0.9900\n",
            "Epoch 560/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0317 - accuracy: 0.9893 - val_loss: 0.1171 - val_accuracy: 0.9867\n",
            "Epoch 561/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0551 - accuracy: 0.9837 - val_loss: 0.0824 - val_accuracy: 0.9833\n",
            "Epoch 562/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0429 - accuracy: 0.9844 - val_loss: 0.1152 - val_accuracy: 0.9833\n",
            "Epoch 563/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0533 - accuracy: 0.9848 - val_loss: 0.0850 - val_accuracy: 0.9900\n",
            "Epoch 564/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0421 - accuracy: 0.9878 - val_loss: 0.0875 - val_accuracy: 0.9833\n",
            "Epoch 565/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 0.0943 - val_accuracy: 0.9867\n",
            "Epoch 566/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0442 - accuracy: 0.9867 - val_loss: 0.1094 - val_accuracy: 0.9900\n",
            "Epoch 567/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0370 - accuracy: 0.9870 - val_loss: 0.0936 - val_accuracy: 0.9867\n",
            "Epoch 568/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0514 - accuracy: 0.9881 - val_loss: 0.0896 - val_accuracy: 0.9867\n",
            "Epoch 569/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0588 - accuracy: 0.9781 - val_loss: 0.0974 - val_accuracy: 0.9900\n",
            "Epoch 570/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.0935 - val_accuracy: 0.9900\n",
            "Epoch 571/1000\n",
            "54/54 [==============================] - 28s 520ms/step - loss: 0.0431 - accuracy: 0.9852 - val_loss: 0.1030 - val_accuracy: 0.9867\n",
            "Epoch 572/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0575 - accuracy: 0.9804 - val_loss: 0.0969 - val_accuracy: 0.9867\n",
            "Epoch 573/1000\n",
            "54/54 [==============================] - 28s 523ms/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.1178 - val_accuracy: 0.9833\n",
            "Epoch 574/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0396 - accuracy: 0.9863 - val_loss: 0.1421 - val_accuracy: 0.9767\n",
            "Epoch 575/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0499 - accuracy: 0.9837 - val_loss: 0.1075 - val_accuracy: 0.9833\n",
            "Epoch 576/1000\n",
            "54/54 [==============================] - 28s 521ms/step - loss: 0.0444 - accuracy: 0.9874 - val_loss: 0.1107 - val_accuracy: 0.9900\n",
            "Epoch 577/1000\n",
            "54/54 [==============================] - 28s 522ms/step - loss: 0.0603 - accuracy: 0.9848 - val_loss: 0.0791 - val_accuracy: 0.9867\n",
            "Epoch 578/1000\n",
            "54/54 [==============================] - 28s 522ms/step - loss: 0.0387 - accuracy: 0.9859 - val_loss: 0.0928 - val_accuracy: 0.9867\n",
            "Epoch 579/1000\n",
            "54/54 [==============================] - 28s 523ms/step - loss: 0.0439 - accuracy: 0.9833 - val_loss: 0.0864 - val_accuracy: 0.9867\n",
            "Epoch 580/1000\n",
            "54/54 [==============================] - 28s 520ms/step - loss: 0.0655 - accuracy: 0.9819 - val_loss: 0.0792 - val_accuracy: 0.9867\n",
            "Epoch 581/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0436 - accuracy: 0.9852 - val_loss: 0.0801 - val_accuracy: 0.9867\n",
            "Epoch 582/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0480 - accuracy: 0.9819 - val_loss: 0.0907 - val_accuracy: 0.9867\n",
            "Epoch 583/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0531 - accuracy: 0.9852 - val_loss: 0.0792 - val_accuracy: 0.9900\n",
            "Epoch 584/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0464 - accuracy: 0.9826 - val_loss: 0.0827 - val_accuracy: 0.9867\n",
            "Epoch 585/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0441 - accuracy: 0.9844 - val_loss: 0.1212 - val_accuracy: 0.9800\n",
            "Epoch 586/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0531 - accuracy: 0.9833 - val_loss: 0.1163 - val_accuracy: 0.9800\n",
            "Epoch 587/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0495 - accuracy: 0.9856 - val_loss: 0.0982 - val_accuracy: 0.9867\n",
            "Epoch 588/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0505 - accuracy: 0.9819 - val_loss: 0.0855 - val_accuracy: 0.9867\n",
            "Epoch 589/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0520 - accuracy: 0.9874 - val_loss: 0.1063 - val_accuracy: 0.9867\n",
            "Epoch 590/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0448 - accuracy: 0.9856 - val_loss: 0.0971 - val_accuracy: 0.9833\n",
            "Epoch 591/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 0.0856 - val_accuracy: 0.9900\n",
            "Epoch 592/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0343 - accuracy: 0.9881 - val_loss: 0.1252 - val_accuracy: 0.9767\n",
            "Epoch 593/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0522 - accuracy: 0.9844 - val_loss: 0.0794 - val_accuracy: 0.9867\n",
            "Epoch 594/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0531 - accuracy: 0.9837 - val_loss: 0.0823 - val_accuracy: 0.9900\n",
            "Epoch 595/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0489 - accuracy: 0.9822 - val_loss: 0.0869 - val_accuracy: 0.9900\n",
            "Epoch 596/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0460 - accuracy: 0.9833 - val_loss: 0.0757 - val_accuracy: 0.9900\n",
            "Epoch 597/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0511 - accuracy: 0.9852 - val_loss: 0.1057 - val_accuracy: 0.9833\n",
            "Epoch 598/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0491 - accuracy: 0.9826 - val_loss: 0.0814 - val_accuracy: 0.9867\n",
            "Epoch 599/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.0837 - val_accuracy: 0.9867\n",
            "Epoch 600/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0458 - accuracy: 0.9863 - val_loss: 0.1004 - val_accuracy: 0.9833\n",
            "Epoch 601/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0501 - accuracy: 0.9856 - val_loss: 0.0674 - val_accuracy: 0.9867\n",
            "Epoch 602/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0451 - accuracy: 0.9867 - val_loss: 0.0676 - val_accuracy: 0.9867\n",
            "Epoch 603/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0371 - accuracy: 0.9881 - val_loss: 0.0695 - val_accuracy: 0.9833\n",
            "Epoch 604/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0400 - accuracy: 0.9881 - val_loss: 0.0808 - val_accuracy: 0.9867\n",
            "Epoch 605/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0541 - accuracy: 0.9837 - val_loss: 0.0661 - val_accuracy: 0.9900\n",
            "Epoch 606/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0460 - accuracy: 0.9867 - val_loss: 0.0816 - val_accuracy: 0.9867\n",
            "Epoch 607/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0413 - accuracy: 0.9856 - val_loss: 0.0866 - val_accuracy: 0.9900\n",
            "Epoch 608/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0492 - accuracy: 0.9863 - val_loss: 0.1032 - val_accuracy: 0.9867\n",
            "Epoch 609/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0612 - accuracy: 0.9819 - val_loss: 0.0800 - val_accuracy: 0.9900\n",
            "Epoch 610/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0552 - accuracy: 0.9800 - val_loss: 0.0819 - val_accuracy: 0.9900\n",
            "Epoch 611/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0367 - accuracy: 0.9874 - val_loss: 0.0940 - val_accuracy: 0.9900\n",
            "Epoch 612/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0530 - accuracy: 0.9837 - val_loss: 0.0755 - val_accuracy: 0.9833\n",
            "Epoch 613/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0483 - accuracy: 0.9822 - val_loss: 0.1149 - val_accuracy: 0.9833\n",
            "Epoch 614/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0426 - accuracy: 0.9874 - val_loss: 0.1244 - val_accuracy: 0.9833\n",
            "Epoch 615/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0577 - accuracy: 0.9826 - val_loss: 0.0892 - val_accuracy: 0.9767\n",
            "Epoch 616/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0515 - accuracy: 0.9844 - val_loss: 0.0808 - val_accuracy: 0.9867\n",
            "Epoch 617/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0383 - accuracy: 0.9859 - val_loss: 0.0943 - val_accuracy: 0.9900\n",
            "Epoch 618/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0427 - accuracy: 0.9852 - val_loss: 0.0909 - val_accuracy: 0.9900\n",
            "Epoch 619/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0485 - accuracy: 0.9844 - val_loss: 0.0861 - val_accuracy: 0.9867\n",
            "Epoch 620/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0532 - accuracy: 0.9819 - val_loss: 0.0800 - val_accuracy: 0.9900\n",
            "Epoch 621/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.0881 - val_accuracy: 0.9833\n",
            "Epoch 622/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0544 - accuracy: 0.9844 - val_loss: 0.0914 - val_accuracy: 0.9900\n",
            "Epoch 623/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0363 - accuracy: 0.9900 - val_loss: 0.0859 - val_accuracy: 0.9867\n",
            "Epoch 624/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0533 - accuracy: 0.9822 - val_loss: 0.0653 - val_accuracy: 0.9900\n",
            "Epoch 625/1000\n",
            "54/54 [==============================] - 28s 520ms/step - loss: 0.0397 - accuracy: 0.9859 - val_loss: 0.0953 - val_accuracy: 0.9867\n",
            "Epoch 626/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0431 - accuracy: 0.9830 - val_loss: 0.0785 - val_accuracy: 0.9867\n",
            "Epoch 627/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0429 - accuracy: 0.9863 - val_loss: 0.0722 - val_accuracy: 0.9833\n",
            "Epoch 628/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0513 - accuracy: 0.9833 - val_loss: 0.0786 - val_accuracy: 0.9867\n",
            "Epoch 629/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0501 - accuracy: 0.9856 - val_loss: 0.0972 - val_accuracy: 0.9833\n",
            "Epoch 630/1000\n",
            "54/54 [==============================] - 27s 495ms/step - loss: 0.0425 - accuracy: 0.9841 - val_loss: 0.0733 - val_accuracy: 0.9900\n",
            "Epoch 631/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0469 - accuracy: 0.9841 - val_loss: 0.0889 - val_accuracy: 0.9867\n",
            "Epoch 632/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.1013 - val_accuracy: 0.9900\n",
            "Epoch 633/1000\n",
            "54/54 [==============================] - 27s 491ms/step - loss: 0.0523 - accuracy: 0.9874 - val_loss: 0.0919 - val_accuracy: 0.9867\n",
            "Epoch 634/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0479 - accuracy: 0.9830 - val_loss: 0.0955 - val_accuracy: 0.9867\n",
            "Epoch 635/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0400 - accuracy: 0.9878 - val_loss: 0.1046 - val_accuracy: 0.9867\n",
            "Epoch 636/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0539 - accuracy: 0.9819 - val_loss: 0.0981 - val_accuracy: 0.9900\n",
            "Epoch 637/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0396 - accuracy: 0.9885 - val_loss: 0.0983 - val_accuracy: 0.9900\n",
            "Epoch 638/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0496 - accuracy: 0.9867 - val_loss: 0.1304 - val_accuracy: 0.9767\n",
            "Epoch 639/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.0791 - val_accuracy: 0.9900\n",
            "Epoch 640/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0510 - accuracy: 0.9811 - val_loss: 0.1014 - val_accuracy: 0.9833\n",
            "Epoch 641/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.1113 - val_accuracy: 0.9867\n",
            "Epoch 642/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0976 - val_accuracy: 0.9867\n",
            "Epoch 643/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0385 - accuracy: 0.9852 - val_loss: 0.0763 - val_accuracy: 0.9900\n",
            "Epoch 644/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0313 - accuracy: 0.9889 - val_loss: 0.1164 - val_accuracy: 0.9867\n",
            "Epoch 645/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0506 - accuracy: 0.9826 - val_loss: 0.1094 - val_accuracy: 0.9867\n",
            "Epoch 646/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0425 - accuracy: 0.9863 - val_loss: 0.0687 - val_accuracy: 0.9900\n",
            "Epoch 647/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0442 - accuracy: 0.9841 - val_loss: 0.0827 - val_accuracy: 0.9867\n",
            "Epoch 648/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0379 - accuracy: 0.9881 - val_loss: 0.0891 - val_accuracy: 0.9900\n",
            "Epoch 649/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0360 - accuracy: 0.9885 - val_loss: 0.0855 - val_accuracy: 0.9900\n",
            "Epoch 650/1000\n",
            "54/54 [==============================] - 27s 493ms/step - loss: 0.0444 - accuracy: 0.9874 - val_loss: 0.1002 - val_accuracy: 0.9900\n",
            "Epoch 651/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0422 - accuracy: 0.9885 - val_loss: 0.0913 - val_accuracy: 0.9833\n",
            "Epoch 652/1000\n",
            "54/54 [==============================] - 27s 495ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 0.0900 - val_accuracy: 0.9833\n",
            "Epoch 653/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0432 - accuracy: 0.9852 - val_loss: 0.1093 - val_accuracy: 0.9833\n",
            "Epoch 654/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0525 - accuracy: 0.9822 - val_loss: 0.1145 - val_accuracy: 0.9800\n",
            "Epoch 655/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0467 - accuracy: 0.9859 - val_loss: 0.0919 - val_accuracy: 0.9833\n",
            "Epoch 656/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0618 - accuracy: 0.9800 - val_loss: 0.1034 - val_accuracy: 0.9867\n",
            "Epoch 657/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.0997 - val_accuracy: 0.9900\n",
            "Epoch 658/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0479 - accuracy: 0.9856 - val_loss: 0.1129 - val_accuracy: 0.9833\n",
            "Epoch 659/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 0.0901 - val_accuracy: 0.9867\n",
            "Epoch 660/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 0.1139 - val_accuracy: 0.9767\n",
            "Epoch 661/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 0.0977 - val_accuracy: 0.9800\n",
            "Epoch 662/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0462 - accuracy: 0.9833 - val_loss: 0.1215 - val_accuracy: 0.9800\n",
            "Epoch 663/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0443 - accuracy: 0.9837 - val_loss: 0.0915 - val_accuracy: 0.9867\n",
            "Epoch 664/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0418 - accuracy: 0.9848 - val_loss: 0.0959 - val_accuracy: 0.9867\n",
            "Epoch 665/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 0.0915 - val_accuracy: 0.9800\n",
            "Epoch 666/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0425 - accuracy: 0.9889 - val_loss: 0.0991 - val_accuracy: 0.9900\n",
            "Epoch 667/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0336 - accuracy: 0.9863 - val_loss: 0.0993 - val_accuracy: 0.9867\n",
            "Epoch 668/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0408 - accuracy: 0.9867 - val_loss: 0.0820 - val_accuracy: 0.9833\n",
            "Epoch 669/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0505 - accuracy: 0.9822 - val_loss: 0.0709 - val_accuracy: 0.9867\n",
            "Epoch 670/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0418 - accuracy: 0.9863 - val_loss: 0.0753 - val_accuracy: 0.9900\n",
            "Epoch 671/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0324 - accuracy: 0.9870 - val_loss: 0.1163 - val_accuracy: 0.9833\n",
            "Epoch 672/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0426 - accuracy: 0.9863 - val_loss: 0.0979 - val_accuracy: 0.9867\n",
            "Epoch 673/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0412 - accuracy: 0.9859 - val_loss: 0.0985 - val_accuracy: 0.9867\n",
            "Epoch 674/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0410 - accuracy: 0.9841 - val_loss: 0.1293 - val_accuracy: 0.9700\n",
            "Epoch 675/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0497 - accuracy: 0.9881 - val_loss: 0.1025 - val_accuracy: 0.9767\n",
            "Epoch 676/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0539 - accuracy: 0.9848 - val_loss: 0.0859 - val_accuracy: 0.9800\n",
            "Epoch 677/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0445 - accuracy: 0.9841 - val_loss: 0.0945 - val_accuracy: 0.9833\n",
            "Epoch 678/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.1072 - val_accuracy: 0.9867\n",
            "Epoch 679/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0431 - accuracy: 0.9848 - val_loss: 0.0830 - val_accuracy: 0.9867\n",
            "Epoch 680/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0486 - accuracy: 0.9822 - val_loss: 0.0731 - val_accuracy: 0.9867\n",
            "Epoch 681/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0370 - accuracy: 0.9844 - val_loss: 0.0959 - val_accuracy: 0.9867\n",
            "Epoch 682/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0425 - accuracy: 0.9859 - val_loss: 0.0826 - val_accuracy: 0.9867\n",
            "Epoch 683/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0498 - accuracy: 0.9830 - val_loss: 0.0977 - val_accuracy: 0.9867\n",
            "Epoch 684/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0431 - accuracy: 0.9863 - val_loss: 0.0816 - val_accuracy: 0.9900\n",
            "Epoch 685/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0378 - accuracy: 0.9848 - val_loss: 0.1134 - val_accuracy: 0.9833\n",
            "Epoch 686/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0514 - accuracy: 0.9804 - val_loss: 0.1003 - val_accuracy: 0.9867\n",
            "Epoch 687/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.0925 - val_accuracy: 0.9900\n",
            "Epoch 688/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0535 - accuracy: 0.9878 - val_loss: 0.1158 - val_accuracy: 0.9867\n",
            "Epoch 689/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0499 - accuracy: 0.9852 - val_loss: 0.0739 - val_accuracy: 0.9867\n",
            "Epoch 690/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0393 - accuracy: 0.9863 - val_loss: 0.0987 - val_accuracy: 0.9900\n",
            "Epoch 691/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 0.1276 - val_accuracy: 0.9800\n",
            "Epoch 692/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0566 - accuracy: 0.9800 - val_loss: 0.0879 - val_accuracy: 0.9800\n",
            "Epoch 693/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0476 - accuracy: 0.9837 - val_loss: 0.1166 - val_accuracy: 0.9833\n",
            "Epoch 694/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0567 - accuracy: 0.9804 - val_loss: 0.0941 - val_accuracy: 0.9867\n",
            "Epoch 695/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0509 - accuracy: 0.9796 - val_loss: 0.0881 - val_accuracy: 0.9867\n",
            "Epoch 696/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.1045 - val_accuracy: 0.9867\n",
            "Epoch 697/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0488 - accuracy: 0.9807 - val_loss: 0.0800 - val_accuracy: 0.9867\n",
            "Epoch 698/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0512 - accuracy: 0.9837 - val_loss: 0.0699 - val_accuracy: 0.9833\n",
            "Epoch 699/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0505 - accuracy: 0.9822 - val_loss: 0.0969 - val_accuracy: 0.9800\n",
            "Epoch 700/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0422 - accuracy: 0.9870 - val_loss: 0.1172 - val_accuracy: 0.9833\n",
            "Epoch 701/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 0.1066 - val_accuracy: 0.9867\n",
            "Epoch 702/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0393 - accuracy: 0.9848 - val_loss: 0.0866 - val_accuracy: 0.9867\n",
            "Epoch 703/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0400 - accuracy: 0.9859 - val_loss: 0.1315 - val_accuracy: 0.9800\n",
            "Epoch 704/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 0.1020 - val_accuracy: 0.9833\n",
            "Epoch 705/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0424 - accuracy: 0.9856 - val_loss: 0.1362 - val_accuracy: 0.9833\n",
            "Epoch 706/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.1094 - val_accuracy: 0.9833\n",
            "Epoch 707/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0501 - accuracy: 0.9822 - val_loss: 0.0787 - val_accuracy: 0.9833\n",
            "Epoch 708/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0494 - accuracy: 0.9841 - val_loss: 0.0812 - val_accuracy: 0.9867\n",
            "Epoch 709/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0524 - accuracy: 0.9841 - val_loss: 0.0829 - val_accuracy: 0.9833\n",
            "Epoch 710/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0380 - accuracy: 0.9874 - val_loss: 0.1502 - val_accuracy: 0.9767\n",
            "Epoch 711/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0397 - accuracy: 0.9852 - val_loss: 0.0877 - val_accuracy: 0.9800\n",
            "Epoch 712/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0555 - accuracy: 0.9815 - val_loss: 0.0706 - val_accuracy: 0.9867\n",
            "Epoch 713/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0489 - accuracy: 0.9859 - val_loss: 0.0794 - val_accuracy: 0.9867\n",
            "Epoch 714/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0432 - accuracy: 0.9848 - val_loss: 0.1056 - val_accuracy: 0.9867\n",
            "Epoch 715/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0424 - accuracy: 0.9848 - val_loss: 0.1164 - val_accuracy: 0.9867\n",
            "Epoch 716/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0541 - accuracy: 0.9852 - val_loss: 0.1146 - val_accuracy: 0.9867\n",
            "Epoch 717/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0382 - accuracy: 0.9870 - val_loss: 0.1015 - val_accuracy: 0.9833\n",
            "Epoch 718/1000\n",
            "54/54 [==============================] - 27s 508ms/step - loss: 0.0531 - accuracy: 0.9830 - val_loss: 0.1233 - val_accuracy: 0.9833\n",
            "Epoch 719/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0421 - accuracy: 0.9848 - val_loss: 0.1238 - val_accuracy: 0.9867\n",
            "Epoch 720/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0362 - accuracy: 0.9893 - val_loss: 0.0959 - val_accuracy: 0.9900\n",
            "Epoch 721/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0469 - accuracy: 0.9837 - val_loss: 0.0823 - val_accuracy: 0.9833\n",
            "Epoch 722/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0501 - accuracy: 0.9826 - val_loss: 0.0947 - val_accuracy: 0.9833\n",
            "Epoch 723/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 0.1009 - val_accuracy: 0.9800\n",
            "Epoch 724/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0399 - accuracy: 0.9863 - val_loss: 0.0921 - val_accuracy: 0.9900\n",
            "Epoch 725/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0456 - accuracy: 0.9815 - val_loss: 0.0979 - val_accuracy: 0.9900\n",
            "Epoch 726/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0472 - accuracy: 0.9830 - val_loss: 0.1038 - val_accuracy: 0.9900\n",
            "Epoch 727/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0314 - accuracy: 0.9878 - val_loss: 0.1137 - val_accuracy: 0.9867\n",
            "Epoch 728/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.1030 - val_accuracy: 0.9900\n",
            "Epoch 729/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0417 - accuracy: 0.9885 - val_loss: 0.0732 - val_accuracy: 0.9833\n",
            "Epoch 730/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0512 - accuracy: 0.9844 - val_loss: 0.0934 - val_accuracy: 0.9833\n",
            "Epoch 731/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 0.1054 - val_accuracy: 0.9867\n",
            "Epoch 732/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0488 - accuracy: 0.9841 - val_loss: 0.0942 - val_accuracy: 0.9833\n",
            "Epoch 733/1000\n",
            "54/54 [==============================] - 28s 520ms/step - loss: 0.0390 - accuracy: 0.9881 - val_loss: 0.0801 - val_accuracy: 0.9900\n",
            "Epoch 734/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0427 - accuracy: 0.9863 - val_loss: 0.1063 - val_accuracy: 0.9900\n",
            "Epoch 735/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0378 - accuracy: 0.9867 - val_loss: 0.0894 - val_accuracy: 0.9867\n",
            "Epoch 736/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0447 - accuracy: 0.9837 - val_loss: 0.1109 - val_accuracy: 0.9900\n",
            "Epoch 737/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0389 - accuracy: 0.9885 - val_loss: 0.0985 - val_accuracy: 0.9867\n",
            "Epoch 738/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0501 - accuracy: 0.9837 - val_loss: 0.0905 - val_accuracy: 0.9867\n",
            "Epoch 739/1000\n",
            "54/54 [==============================] - 28s 520ms/step - loss: 0.0387 - accuracy: 0.9889 - val_loss: 0.0908 - val_accuracy: 0.9833\n",
            "Epoch 740/1000\n",
            "54/54 [==============================] - 28s 525ms/step - loss: 0.0390 - accuracy: 0.9896 - val_loss: 0.0941 - val_accuracy: 0.9867\n",
            "Epoch 741/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0491 - accuracy: 0.9852 - val_loss: 0.0684 - val_accuracy: 0.9833\n",
            "Epoch 742/1000\n",
            "54/54 [==============================] - 28s 521ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 0.0976 - val_accuracy: 0.9867\n",
            "Epoch 743/1000\n",
            "54/54 [==============================] - 28s 520ms/step - loss: 0.0449 - accuracy: 0.9867 - val_loss: 0.0760 - val_accuracy: 0.9833\n",
            "Epoch 744/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0479 - accuracy: 0.9844 - val_loss: 0.1077 - val_accuracy: 0.9900\n",
            "Epoch 745/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0440 - accuracy: 0.9870 - val_loss: 0.0961 - val_accuracy: 0.9867\n",
            "Epoch 746/1000\n",
            "54/54 [==============================] - 28s 515ms/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.1154 - val_accuracy: 0.9867\n",
            "Epoch 747/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0423 - accuracy: 0.9859 - val_loss: 0.1002 - val_accuracy: 0.9867\n",
            "Epoch 748/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.1038 - val_accuracy: 0.9867\n",
            "Epoch 749/1000\n",
            "54/54 [==============================] - 28s 518ms/step - loss: 0.0417 - accuracy: 0.9848 - val_loss: 0.1098 - val_accuracy: 0.9867\n",
            "Epoch 750/1000\n",
            "54/54 [==============================] - 28s 521ms/step - loss: 0.0409 - accuracy: 0.9867 - val_loss: 0.0933 - val_accuracy: 0.9833\n",
            "Epoch 751/1000\n",
            "54/54 [==============================] - 28s 523ms/step - loss: 0.0493 - accuracy: 0.9852 - val_loss: 0.0996 - val_accuracy: 0.9867\n",
            "Epoch 752/1000\n",
            "54/54 [==============================] - 28s 517ms/step - loss: 0.0475 - accuracy: 0.9856 - val_loss: 0.0810 - val_accuracy: 0.9867\n",
            "Epoch 753/1000\n",
            "54/54 [==============================] - 28s 521ms/step - loss: 0.0408 - accuracy: 0.9859 - val_loss: 0.1348 - val_accuracy: 0.9833\n",
            "Epoch 754/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0458 - accuracy: 0.9841 - val_loss: 0.0857 - val_accuracy: 0.9900\n",
            "Epoch 755/1000\n",
            "54/54 [==============================] - 28s 520ms/step - loss: 0.0407 - accuracy: 0.9852 - val_loss: 0.1251 - val_accuracy: 0.9833\n",
            "Epoch 756/1000\n",
            "54/54 [==============================] - 28s 519ms/step - loss: 0.0368 - accuracy: 0.9889 - val_loss: 0.1011 - val_accuracy: 0.9867\n",
            "Epoch 757/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.0977 - val_accuracy: 0.9867\n",
            "Epoch 758/1000\n",
            "54/54 [==============================] - 28s 512ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.0925 - val_accuracy: 0.9800\n",
            "Epoch 759/1000\n",
            "54/54 [==============================] - 28s 516ms/step - loss: 0.0461 - accuracy: 0.9841 - val_loss: 0.1242 - val_accuracy: 0.9833\n",
            "Epoch 760/1000\n",
            "54/54 [==============================] - 28s 510ms/step - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.0956 - val_accuracy: 0.9833\n",
            "Epoch 761/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0317 - accuracy: 0.9874 - val_loss: 0.1106 - val_accuracy: 0.9833\n",
            "Epoch 762/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0437 - accuracy: 0.9885 - val_loss: 0.0971 - val_accuracy: 0.9900\n",
            "Epoch 763/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0397 - accuracy: 0.9848 - val_loss: 0.0746 - val_accuracy: 0.9900\n",
            "Epoch 764/1000\n",
            "54/54 [==============================] - 28s 511ms/step - loss: 0.0388 - accuracy: 0.9867 - val_loss: 0.0825 - val_accuracy: 0.9867\n",
            "Epoch 765/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 0.0937 - val_accuracy: 0.9867\n",
            "Epoch 766/1000\n",
            "54/54 [==============================] - 28s 513ms/step - loss: 0.0385 - accuracy: 0.9852 - val_loss: 0.1100 - val_accuracy: 0.9833\n",
            "Epoch 767/1000\n",
            "54/54 [==============================] - 28s 514ms/step - loss: 0.0392 - accuracy: 0.9863 - val_loss: 0.0991 - val_accuracy: 0.9833\n",
            "Epoch 768/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0380 - accuracy: 0.9844 - val_loss: 0.0814 - val_accuracy: 0.9867\n",
            "Epoch 769/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0373 - accuracy: 0.9863 - val_loss: 0.1149 - val_accuracy: 0.9867\n",
            "Epoch 770/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0401 - accuracy: 0.9859 - val_loss: 0.1161 - val_accuracy: 0.9833\n",
            "Epoch 771/1000\n",
            "54/54 [==============================] - 27s 507ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.0986 - val_accuracy: 0.9833\n",
            "Epoch 772/1000\n",
            "54/54 [==============================] - 27s 503ms/step - loss: 0.0579 - accuracy: 0.9844 - val_loss: 0.0752 - val_accuracy: 0.9833\n",
            "Epoch 773/1000\n",
            "54/54 [==============================] - 27s 509ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.0926 - val_accuracy: 0.9867\n",
            "Epoch 774/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0419 - accuracy: 0.9856 - val_loss: 0.1042 - val_accuracy: 0.9800\n",
            "Epoch 775/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0478 - accuracy: 0.9852 - val_loss: 0.0809 - val_accuracy: 0.9833\n",
            "Epoch 776/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0366 - accuracy: 0.9859 - val_loss: 0.0988 - val_accuracy: 0.9833\n",
            "Epoch 777/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.1049 - val_accuracy: 0.9900\n",
            "Epoch 778/1000\n",
            "54/54 [==============================] - 26s 490ms/step - loss: 0.0359 - accuracy: 0.9859 - val_loss: 0.1097 - val_accuracy: 0.9800\n",
            "Epoch 779/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0490 - accuracy: 0.9830 - val_loss: 0.1225 - val_accuracy: 0.9833\n",
            "Epoch 780/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0323 - accuracy: 0.9878 - val_loss: 0.1109 - val_accuracy: 0.9867\n",
            "Epoch 781/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0392 - accuracy: 0.9852 - val_loss: 0.1026 - val_accuracy: 0.9833\n",
            "Epoch 782/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0415 - accuracy: 0.9856 - val_loss: 0.1113 - val_accuracy: 0.9867\n",
            "Epoch 783/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0363 - accuracy: 0.9870 - val_loss: 0.1131 - val_accuracy: 0.9833\n",
            "Epoch 784/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0389 - accuracy: 0.9859 - val_loss: 0.1148 - val_accuracy: 0.9833\n",
            "Epoch 785/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0438 - accuracy: 0.9870 - val_loss: 0.0892 - val_accuracy: 0.9867\n",
            "Epoch 786/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0435 - accuracy: 0.9878 - val_loss: 0.1140 - val_accuracy: 0.9867\n",
            "Epoch 787/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0480 - accuracy: 0.9811 - val_loss: 0.0979 - val_accuracy: 0.9867\n",
            "Epoch 788/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0403 - accuracy: 0.9878 - val_loss: 0.0847 - val_accuracy: 0.9900\n",
            "Epoch 789/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0411 - accuracy: 0.9844 - val_loss: 0.0902 - val_accuracy: 0.9867\n",
            "Epoch 790/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.0386 - accuracy: 0.9867 - val_loss: 0.1062 - val_accuracy: 0.9867\n",
            "Epoch 791/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0423 - accuracy: 0.9881 - val_loss: 0.1095 - val_accuracy: 0.9833\n",
            "Epoch 792/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 0.0986 - val_accuracy: 0.9900\n",
            "Epoch 793/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0449 - accuracy: 0.9856 - val_loss: 0.0915 - val_accuracy: 0.9867\n",
            "Epoch 794/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.1012 - val_accuracy: 0.9867\n",
            "Epoch 795/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0359 - accuracy: 0.9867 - val_loss: 0.1149 - val_accuracy: 0.9833\n",
            "Epoch 796/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0367 - accuracy: 0.9848 - val_loss: 0.1182 - val_accuracy: 0.9800\n",
            "Epoch 797/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0379 - accuracy: 0.9878 - val_loss: 0.1431 - val_accuracy: 0.9800\n",
            "Epoch 798/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0344 - accuracy: 0.9900 - val_loss: 0.0838 - val_accuracy: 0.9833\n",
            "Epoch 799/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0380 - accuracy: 0.9867 - val_loss: 0.1034 - val_accuracy: 0.9800\n",
            "Epoch 800/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 0.1013 - val_accuracy: 0.9900\n",
            "Epoch 801/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0369 - accuracy: 0.9848 - val_loss: 0.1509 - val_accuracy: 0.9867\n",
            "Epoch 802/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0494 - accuracy: 0.9837 - val_loss: 0.1064 - val_accuracy: 0.9833\n",
            "Epoch 803/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0511 - accuracy: 0.9841 - val_loss: 0.1100 - val_accuracy: 0.9833\n",
            "Epoch 804/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0381 - accuracy: 0.9848 - val_loss: 0.1215 - val_accuracy: 0.9800\n",
            "Epoch 805/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.1203 - val_accuracy: 0.9833\n",
            "Epoch 806/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0336 - accuracy: 0.9867 - val_loss: 0.1143 - val_accuracy: 0.9800\n",
            "Epoch 807/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0371 - accuracy: 0.9889 - val_loss: 0.0850 - val_accuracy: 0.9867\n",
            "Epoch 808/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0374 - accuracy: 0.9863 - val_loss: 0.0921 - val_accuracy: 0.9800\n",
            "Epoch 809/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.1211 - val_accuracy: 0.9867\n",
            "Epoch 810/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0413 - accuracy: 0.9859 - val_loss: 0.1038 - val_accuracy: 0.9833\n",
            "Epoch 811/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0440 - accuracy: 0.9870 - val_loss: 0.0867 - val_accuracy: 0.9867\n",
            "Epoch 812/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.0910 - val_accuracy: 0.9867\n",
            "Epoch 813/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0549 - accuracy: 0.9852 - val_loss: 0.0888 - val_accuracy: 0.9833\n",
            "Epoch 814/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0439 - accuracy: 0.9841 - val_loss: 0.1150 - val_accuracy: 0.9833\n",
            "Epoch 815/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0507 - accuracy: 0.9826 - val_loss: 0.0745 - val_accuracy: 0.9900\n",
            "Epoch 816/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0388 - accuracy: 0.9856 - val_loss: 0.0963 - val_accuracy: 0.9867\n",
            "Epoch 817/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0500 - accuracy: 0.9837 - val_loss: 0.1032 - val_accuracy: 0.9900\n",
            "Epoch 818/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0480 - accuracy: 0.9807 - val_loss: 0.0967 - val_accuracy: 0.9833\n",
            "Epoch 819/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0363 - accuracy: 0.9856 - val_loss: 0.1250 - val_accuracy: 0.9800\n",
            "Epoch 820/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0327 - accuracy: 0.9885 - val_loss: 0.0912 - val_accuracy: 0.9833\n",
            "Epoch 821/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0347 - accuracy: 0.9889 - val_loss: 0.0993 - val_accuracy: 0.9833\n",
            "Epoch 822/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0419 - accuracy: 0.9885 - val_loss: 0.1007 - val_accuracy: 0.9900\n",
            "Epoch 823/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0331 - accuracy: 0.9915 - val_loss: 0.1041 - val_accuracy: 0.9867\n",
            "Epoch 824/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0377 - accuracy: 0.9856 - val_loss: 0.0847 - val_accuracy: 0.9867\n",
            "Epoch 825/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0294 - accuracy: 0.9881 - val_loss: 0.0973 - val_accuracy: 0.9833\n",
            "Epoch 826/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.1006 - val_accuracy: 0.9833\n",
            "Epoch 827/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.1177 - val_accuracy: 0.9833\n",
            "Epoch 828/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0322 - accuracy: 0.9878 - val_loss: 0.0983 - val_accuracy: 0.9900\n",
            "Epoch 829/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.1051 - val_accuracy: 0.9833\n",
            "Epoch 830/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 0.1130 - val_accuracy: 0.9867\n",
            "Epoch 831/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0343 - accuracy: 0.9863 - val_loss: 0.1083 - val_accuracy: 0.9900\n",
            "Epoch 832/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0405 - accuracy: 0.9867 - val_loss: 0.1130 - val_accuracy: 0.9833\n",
            "Epoch 833/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0378 - accuracy: 0.9844 - val_loss: 0.1323 - val_accuracy: 0.9867\n",
            "Epoch 834/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0433 - accuracy: 0.9841 - val_loss: 0.1218 - val_accuracy: 0.9867\n",
            "Epoch 835/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.1022 - val_accuracy: 0.9800\n",
            "Epoch 836/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0359 - accuracy: 0.9881 - val_loss: 0.0978 - val_accuracy: 0.9867\n",
            "Epoch 837/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.1158 - val_accuracy: 0.9833\n",
            "Epoch 838/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.1163 - val_accuracy: 0.9833\n",
            "Epoch 839/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0385 - accuracy: 0.9893 - val_loss: 0.1109 - val_accuracy: 0.9833\n",
            "Epoch 840/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.1143 - val_accuracy: 0.9900\n",
            "Epoch 841/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0332 - accuracy: 0.9885 - val_loss: 0.0949 - val_accuracy: 0.9900\n",
            "Epoch 842/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.0948 - val_accuracy: 0.9867\n",
            "Epoch 843/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0392 - accuracy: 0.9878 - val_loss: 0.0891 - val_accuracy: 0.9900\n",
            "Epoch 844/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 0.1071 - val_accuracy: 0.9900\n",
            "Epoch 845/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0516 - accuracy: 0.9856 - val_loss: 0.1029 - val_accuracy: 0.9867\n",
            "Epoch 846/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0478 - accuracy: 0.9848 - val_loss: 0.0776 - val_accuracy: 0.9867\n",
            "Epoch 847/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0343 - accuracy: 0.9837 - val_loss: 0.1020 - val_accuracy: 0.9900\n",
            "Epoch 848/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0429 - accuracy: 0.9833 - val_loss: 0.1181 - val_accuracy: 0.9867\n",
            "Epoch 849/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0456 - accuracy: 0.9837 - val_loss: 0.1124 - val_accuracy: 0.9833\n",
            "Epoch 850/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0433 - accuracy: 0.9863 - val_loss: 0.0967 - val_accuracy: 0.9833\n",
            "Epoch 851/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0452 - accuracy: 0.9874 - val_loss: 0.0887 - val_accuracy: 0.9833\n",
            "Epoch 852/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0429 - accuracy: 0.9837 - val_loss: 0.0983 - val_accuracy: 0.9833\n",
            "Epoch 853/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.0981 - val_accuracy: 0.9867\n",
            "Epoch 854/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0431 - accuracy: 0.9841 - val_loss: 0.0877 - val_accuracy: 0.9833\n",
            "Epoch 855/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0362 - accuracy: 0.9893 - val_loss: 0.1004 - val_accuracy: 0.9800\n",
            "Epoch 856/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0302 - accuracy: 0.9896 - val_loss: 0.1039 - val_accuracy: 0.9833\n",
            "Epoch 857/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0366 - accuracy: 0.9881 - val_loss: 0.1144 - val_accuracy: 0.9833\n",
            "Epoch 858/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0353 - accuracy: 0.9870 - val_loss: 0.1058 - val_accuracy: 0.9833\n",
            "Epoch 859/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.0998 - val_accuracy: 0.9833\n",
            "Epoch 860/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0329 - accuracy: 0.9881 - val_loss: 0.1034 - val_accuracy: 0.9800\n",
            "Epoch 861/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0399 - accuracy: 0.9856 - val_loss: 0.1010 - val_accuracy: 0.9867\n",
            "Epoch 862/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 0.0963 - val_accuracy: 0.9833\n",
            "Epoch 863/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.1074 - val_accuracy: 0.9833\n",
            "Epoch 864/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0438 - accuracy: 0.9863 - val_loss: 0.0972 - val_accuracy: 0.9867\n",
            "Epoch 865/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0347 - accuracy: 0.9863 - val_loss: 0.0702 - val_accuracy: 0.9900\n",
            "Epoch 866/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0404 - accuracy: 0.9863 - val_loss: 0.0887 - val_accuracy: 0.9833\n",
            "Epoch 867/1000\n",
            "54/54 [==============================] - 27s 493ms/step - loss: 0.0305 - accuracy: 0.9881 - val_loss: 0.1107 - val_accuracy: 0.9867\n",
            "Epoch 868/1000\n",
            "54/54 [==============================] - 27s 491ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.1085 - val_accuracy: 0.9867\n",
            "Epoch 869/1000\n",
            "54/54 [==============================] - 26s 491ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.0659 - val_accuracy: 0.9833\n",
            "Epoch 870/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0379 - accuracy: 0.9870 - val_loss: 0.0682 - val_accuracy: 0.9900\n",
            "Epoch 871/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0380 - accuracy: 0.9874 - val_loss: 0.0785 - val_accuracy: 0.9900\n",
            "Epoch 872/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0381 - accuracy: 0.9863 - val_loss: 0.0820 - val_accuracy: 0.9900\n",
            "Epoch 873/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0355 - accuracy: 0.9852 - val_loss: 0.0914 - val_accuracy: 0.9867\n",
            "Epoch 874/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0434 - accuracy: 0.9852 - val_loss: 0.0831 - val_accuracy: 0.9833\n",
            "Epoch 875/1000\n",
            "54/54 [==============================] - 27s 497ms/step - loss: 0.0445 - accuracy: 0.9852 - val_loss: 0.0953 - val_accuracy: 0.9900\n",
            "Epoch 876/1000\n",
            "54/54 [==============================] - 27s 496ms/step - loss: 0.0435 - accuracy: 0.9878 - val_loss: 0.0857 - val_accuracy: 0.9867\n",
            "Epoch 877/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0568 - accuracy: 0.9800 - val_loss: 0.0638 - val_accuracy: 0.9933\n",
            "Epoch 878/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0432 - accuracy: 0.9833 - val_loss: 0.0723 - val_accuracy: 0.9900\n",
            "Epoch 879/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0997 - val_accuracy: 0.9867\n",
            "Epoch 880/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.0849 - val_accuracy: 0.9900\n",
            "Epoch 881/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0394 - accuracy: 0.9859 - val_loss: 0.0770 - val_accuracy: 0.9867\n",
            "Epoch 882/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0438 - accuracy: 0.9848 - val_loss: 0.0769 - val_accuracy: 0.9833\n",
            "Epoch 883/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0378 - accuracy: 0.9848 - val_loss: 0.0693 - val_accuracy: 0.9867\n",
            "Epoch 884/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.0877 - val_accuracy: 0.9900\n",
            "Epoch 885/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.0910 - val_accuracy: 0.9867\n",
            "Epoch 886/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 0.1025 - val_accuracy: 0.9867\n",
            "Epoch 887/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0451 - accuracy: 0.9841 - val_loss: 0.1073 - val_accuracy: 0.9867\n",
            "Epoch 888/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0406 - accuracy: 0.9863 - val_loss: 0.1010 - val_accuracy: 0.9900\n",
            "Epoch 889/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0347 - accuracy: 0.9856 - val_loss: 0.0835 - val_accuracy: 0.9867\n",
            "Epoch 890/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0446 - accuracy: 0.9870 - val_loss: 0.0872 - val_accuracy: 0.9833\n",
            "Epoch 891/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0338 - accuracy: 0.9915 - val_loss: 0.0878 - val_accuracy: 0.9833\n",
            "Epoch 892/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.0975 - val_accuracy: 0.9833\n",
            "Epoch 893/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0426 - accuracy: 0.9878 - val_loss: 0.0900 - val_accuracy: 0.9900\n",
            "Epoch 894/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0416 - accuracy: 0.9885 - val_loss: 0.1141 - val_accuracy: 0.9867\n",
            "Epoch 895/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.1128 - val_accuracy: 0.9867\n",
            "Epoch 896/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0400 - accuracy: 0.9863 - val_loss: 0.0893 - val_accuracy: 0.9900\n",
            "Epoch 897/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0410 - accuracy: 0.9837 - val_loss: 0.0799 - val_accuracy: 0.9900\n",
            "Epoch 898/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0354 - accuracy: 0.9867 - val_loss: 0.0849 - val_accuracy: 0.9900\n",
            "Epoch 899/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0284 - accuracy: 0.9926 - val_loss: 0.1077 - val_accuracy: 0.9867\n",
            "Epoch 900/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0359 - accuracy: 0.9881 - val_loss: 0.1036 - val_accuracy: 0.9833\n",
            "Epoch 901/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.1005 - val_accuracy: 0.9833\n",
            "Epoch 902/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 0.1062 - val_accuracy: 0.9900\n",
            "Epoch 903/1000\n",
            "54/54 [==============================] - 26s 477ms/step - loss: 0.0503 - accuracy: 0.9848 - val_loss: 0.0844 - val_accuracy: 0.9867\n",
            "Epoch 904/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0407 - accuracy: 0.9852 - val_loss: 0.0963 - val_accuracy: 0.9867\n",
            "Epoch 905/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0365 - accuracy: 0.9885 - val_loss: 0.0740 - val_accuracy: 0.9867\n",
            "Epoch 906/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0393 - accuracy: 0.9837 - val_loss: 0.0965 - val_accuracy: 0.9833\n",
            "Epoch 907/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0472 - accuracy: 0.9822 - val_loss: 0.1081 - val_accuracy: 0.9867\n",
            "Epoch 908/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 0.1130 - val_accuracy: 0.9800\n",
            "Epoch 909/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0374 - accuracy: 0.9859 - val_loss: 0.1166 - val_accuracy: 0.9833\n",
            "Epoch 910/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.1187 - val_accuracy: 0.9833\n",
            "Epoch 911/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0393 - accuracy: 0.9885 - val_loss: 0.1007 - val_accuracy: 0.9833\n",
            "Epoch 912/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0448 - accuracy: 0.9870 - val_loss: 0.0922 - val_accuracy: 0.9833\n",
            "Epoch 913/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0573 - accuracy: 0.9793 - val_loss: 0.1222 - val_accuracy: 0.9767\n",
            "Epoch 914/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0432 - accuracy: 0.9867 - val_loss: 0.0753 - val_accuracy: 0.9867\n",
            "Epoch 915/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0415 - accuracy: 0.9878 - val_loss: 0.0752 - val_accuracy: 0.9867\n",
            "Epoch 916/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0326 - accuracy: 0.9889 - val_loss: 0.0767 - val_accuracy: 0.9867\n",
            "Epoch 917/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.0905 - val_accuracy: 0.9900\n",
            "Epoch 918/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0306 - accuracy: 0.9889 - val_loss: 0.0848 - val_accuracy: 0.9867\n",
            "Epoch 919/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 0.0825 - val_accuracy: 0.9833\n",
            "Epoch 920/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 0.1055 - val_accuracy: 0.9833\n",
            "Epoch 921/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.1040 - val_accuracy: 0.9867\n",
            "Epoch 922/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.0720 - val_accuracy: 0.9900\n",
            "Epoch 923/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0292 - accuracy: 0.9889 - val_loss: 0.0876 - val_accuracy: 0.9900\n",
            "Epoch 924/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0474 - accuracy: 0.9830 - val_loss: 0.0771 - val_accuracy: 0.9867\n",
            "Epoch 925/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0354 - accuracy: 0.9881 - val_loss: 0.0810 - val_accuracy: 0.9867\n",
            "Epoch 926/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0846 - val_accuracy: 0.9833\n",
            "Epoch 927/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0315 - accuracy: 0.9885 - val_loss: 0.0952 - val_accuracy: 0.9833\n",
            "Epoch 928/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0330 - accuracy: 0.9878 - val_loss: 0.0823 - val_accuracy: 0.9833\n",
            "Epoch 929/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 0.0884 - val_accuracy: 0.9833\n",
            "Epoch 930/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0275 - accuracy: 0.9904 - val_loss: 0.1061 - val_accuracy: 0.9900\n",
            "Epoch 931/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.0801 - val_accuracy: 0.9867\n",
            "Epoch 932/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0304 - accuracy: 0.9922 - val_loss: 0.0982 - val_accuracy: 0.9833\n",
            "Epoch 933/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0435 - accuracy: 0.9859 - val_loss: 0.0971 - val_accuracy: 0.9833\n",
            "Epoch 934/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0429 - accuracy: 0.9859 - val_loss: 0.1050 - val_accuracy: 0.9900\n",
            "Epoch 935/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0371 - accuracy: 0.9867 - val_loss: 0.1059 - val_accuracy: 0.9833\n",
            "Epoch 936/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0307 - accuracy: 0.9885 - val_loss: 0.1290 - val_accuracy: 0.9867\n",
            "Epoch 937/1000\n",
            "54/54 [==============================] - 27s 498ms/step - loss: 0.0362 - accuracy: 0.9863 - val_loss: 0.1323 - val_accuracy: 0.9900\n",
            "Epoch 938/1000\n",
            "54/54 [==============================] - 27s 491ms/step - loss: 0.0440 - accuracy: 0.9830 - val_loss: 0.1357 - val_accuracy: 0.9867\n",
            "Epoch 939/1000\n",
            "54/54 [==============================] - 27s 492ms/step - loss: 0.0404 - accuracy: 0.9852 - val_loss: 0.1146 - val_accuracy: 0.9833\n",
            "Epoch 940/1000\n",
            "54/54 [==============================] - 27s 499ms/step - loss: 0.0372 - accuracy: 0.9889 - val_loss: 0.1089 - val_accuracy: 0.9833\n",
            "Epoch 941/1000\n",
            "54/54 [==============================] - 27s 500ms/step - loss: 0.0314 - accuracy: 0.9889 - val_loss: 0.1069 - val_accuracy: 0.9833\n",
            "Epoch 942/1000\n",
            "54/54 [==============================] - 27s 502ms/step - loss: 0.0282 - accuracy: 0.9919 - val_loss: 0.0988 - val_accuracy: 0.9833\n",
            "Epoch 943/1000\n",
            "54/54 [==============================] - 27s 506ms/step - loss: 0.0447 - accuracy: 0.9837 - val_loss: 0.0860 - val_accuracy: 0.9833\n",
            "Epoch 944/1000\n",
            "54/54 [==============================] - 27s 505ms/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0816 - val_accuracy: 0.9833\n",
            "Epoch 945/1000\n",
            "54/54 [==============================] - 27s 501ms/step - loss: 0.0307 - accuracy: 0.9881 - val_loss: 0.0905 - val_accuracy: 0.9833\n",
            "Epoch 946/1000\n",
            "54/54 [==============================] - 27s 504ms/step - loss: 0.0354 - accuracy: 0.9870 - val_loss: 0.1006 - val_accuracy: 0.9867\n",
            "Epoch 947/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 0.1111 - val_accuracy: 0.9867\n",
            "Epoch 948/1000\n",
            "54/54 [==============================] - 26s 489ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0875 - val_accuracy: 0.9867\n",
            "Epoch 949/1000\n",
            "54/54 [==============================] - 27s 494ms/step - loss: 0.0463 - accuracy: 0.9822 - val_loss: 0.0882 - val_accuracy: 0.9867\n",
            "Epoch 950/1000\n",
            "54/54 [==============================] - 27s 491ms/step - loss: 0.0357 - accuracy: 0.9859 - val_loss: 0.1017 - val_accuracy: 0.9867\n",
            "Epoch 951/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.1138 - val_accuracy: 0.9867\n",
            "Epoch 952/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0369 - accuracy: 0.9844 - val_loss: 0.1287 - val_accuracy: 0.9867\n",
            "Epoch 953/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 0.1172 - val_accuracy: 0.9867\n",
            "Epoch 954/1000\n",
            "54/54 [==============================] - 26s 488ms/step - loss: 0.0396 - accuracy: 0.9859 - val_loss: 0.1086 - val_accuracy: 0.9800\n",
            "Epoch 955/1000\n",
            "54/54 [==============================] - 26s 484ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.1147 - val_accuracy: 0.9867\n",
            "Epoch 956/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0390 - accuracy: 0.9889 - val_loss: 0.1226 - val_accuracy: 0.9800\n",
            "Epoch 957/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 0.1064 - val_accuracy: 0.9900\n",
            "Epoch 958/1000\n",
            "54/54 [==============================] - 26s 487ms/step - loss: 0.0471 - accuracy: 0.9837 - val_loss: 0.1066 - val_accuracy: 0.9800\n",
            "Epoch 959/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0376 - accuracy: 0.9870 - val_loss: 0.0950 - val_accuracy: 0.9833\n",
            "Epoch 960/1000\n",
            "54/54 [==============================] - 26s 486ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.0987 - val_accuracy: 0.9833\n",
            "Epoch 961/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0338 - accuracy: 0.9885 - val_loss: 0.1021 - val_accuracy: 0.9833\n",
            "Epoch 962/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0441 - accuracy: 0.9867 - val_loss: 0.1375 - val_accuracy: 0.9800\n",
            "Epoch 963/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0833 - val_accuracy: 0.9867\n",
            "Epoch 964/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.0994 - val_accuracy: 0.9800\n",
            "Epoch 965/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0342 - accuracy: 0.9874 - val_loss: 0.1114 - val_accuracy: 0.9900\n",
            "Epoch 966/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0451 - accuracy: 0.9837 - val_loss: 0.1028 - val_accuracy: 0.9833\n",
            "Epoch 967/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0357 - accuracy: 0.9874 - val_loss: 0.0977 - val_accuracy: 0.9833\n",
            "Epoch 968/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.0984 - val_accuracy: 0.9833\n",
            "Epoch 969/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0262 - accuracy: 0.9904 - val_loss: 0.1095 - val_accuracy: 0.9833\n",
            "Epoch 970/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0339 - accuracy: 0.9881 - val_loss: 0.0946 - val_accuracy: 0.9833\n",
            "Epoch 971/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0278 - accuracy: 0.9904 - val_loss: 0.1008 - val_accuracy: 0.9833\n",
            "Epoch 972/1000\n",
            "54/54 [==============================] - 26s 485ms/step - loss: 0.0393 - accuracy: 0.9881 - val_loss: 0.0908 - val_accuracy: 0.9867\n",
            "Epoch 973/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 0.0980 - val_accuracy: 0.9833\n",
            "Epoch 974/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.0885 - val_accuracy: 0.9867\n",
            "Epoch 975/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0322 - accuracy: 0.9919 - val_loss: 0.0885 - val_accuracy: 0.9867\n",
            "Epoch 976/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0311 - accuracy: 0.9885 - val_loss: 0.1066 - val_accuracy: 0.9833\n",
            "Epoch 977/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0392 - accuracy: 0.9907 - val_loss: 0.0842 - val_accuracy: 0.9833\n",
            "Epoch 978/1000\n",
            "54/54 [==============================] - 26s 476ms/step - loss: 0.0366 - accuracy: 0.9896 - val_loss: 0.1071 - val_accuracy: 0.9833\n",
            "Epoch 979/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0432 - accuracy: 0.9837 - val_loss: 0.1072 - val_accuracy: 0.9833\n",
            "Epoch 980/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0437 - accuracy: 0.9837 - val_loss: 0.0930 - val_accuracy: 0.9833\n",
            "Epoch 981/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.0935 - val_accuracy: 0.9833\n",
            "Epoch 982/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0369 - accuracy: 0.9885 - val_loss: 0.0968 - val_accuracy: 0.9833\n",
            "Epoch 983/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0436 - accuracy: 0.9874 - val_loss: 0.0911 - val_accuracy: 0.9833\n",
            "Epoch 984/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0347 - accuracy: 0.9870 - val_loss: 0.0843 - val_accuracy: 0.9833\n",
            "Epoch 985/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0333 - accuracy: 0.9863 - val_loss: 0.0802 - val_accuracy: 0.9867\n",
            "Epoch 986/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0289 - accuracy: 0.9893 - val_loss: 0.0949 - val_accuracy: 0.9833\n",
            "Epoch 987/1000\n",
            "54/54 [==============================] - 26s 478ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0912 - val_accuracy: 0.9833\n",
            "Epoch 988/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.1085 - val_accuracy: 0.9800\n",
            "Epoch 989/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0452 - accuracy: 0.9844 - val_loss: 0.1021 - val_accuracy: 0.9833\n",
            "Epoch 990/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0418 - accuracy: 0.9856 - val_loss: 0.0906 - val_accuracy: 0.9833\n",
            "Epoch 991/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0388 - accuracy: 0.9859 - val_loss: 0.0984 - val_accuracy: 0.9833\n",
            "Epoch 992/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 0.0913 - val_accuracy: 0.9867\n",
            "Epoch 993/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0370 - accuracy: 0.9859 - val_loss: 0.1103 - val_accuracy: 0.9867\n",
            "Epoch 994/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0316 - accuracy: 0.9856 - val_loss: 0.1045 - val_accuracy: 0.9833\n",
            "Epoch 995/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.1119 - val_accuracy: 0.9867\n",
            "Epoch 996/1000\n",
            "54/54 [==============================] - 26s 479ms/step - loss: 0.0288 - accuracy: 0.9900 - val_loss: 0.1089 - val_accuracy: 0.9833\n",
            "Epoch 997/1000\n",
            "54/54 [==============================] - 26s 480ms/step - loss: 0.0421 - accuracy: 0.9874 - val_loss: 0.1017 - val_accuracy: 0.9833\n",
            "Epoch 998/1000\n",
            "54/54 [==============================] - 26s 483ms/step - loss: 0.0439 - accuracy: 0.9867 - val_loss: 0.0994 - val_accuracy: 0.9833\n",
            "Epoch 999/1000\n",
            "54/54 [==============================] - 26s 481ms/step - loss: 0.0430 - accuracy: 0.9844 - val_loss: 0.0794 - val_accuracy: 0.9867\n",
            "Epoch 1000/1000\n",
            "54/54 [==============================] - 26s 482ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 0.0941 - val_accuracy: 0.9867\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.99      0.98      0.99       150\n",
            "         yes       0.98      0.99      0.99       150\n",
            "\n",
            "    accuracy                           0.99       300\n",
            "   macro avg       0.99      0.99      0.99       300\n",
            "weighted avg       0.99      0.99      0.99       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvNuAz0j2Dbz"
      },
      "source": [
        "#Saving the model that has been made"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxeClOJ_z6c6",
        "outputId": "94871132-1489-44ac-c3f0-8ded85d3549c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"[INFO] saving mask detector model...\")\n",
        "model.save(\"tumor_detector.model\", save_format=\"h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] saving mask detector model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLkurcsOTOf9"
      },
      "source": [
        "# Plotting the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDkyy6391cWz",
        "outputId": "fa79fd65-3e65-4540-c407-15754a84ce63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJfy3P2sTvEH"
      },
      "source": [
        "# Main Brain Tumour Detection Code from MRI scan\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHgYGBk1ViYy",
        "outputId": "3ebb2166-aaba-4704-bbce-8ae0c70603e7",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "model_path = r\"/content/drive/My Drive/brain_tumor_dataset/tumor_detector.model\"\n",
        "tumorNet = load_model(model_path)\n",
        "\n",
        "x = files.upload()\n",
        "path = ''\n",
        "for key, val in x.items():\n",
        "  path=key\n",
        "\n",
        "img = load_img(path, target_size=(224, 224))\n",
        "img = img_to_array(img)\n",
        "img = preprocess_input(img)\n",
        "I = [img]\n",
        "I = np.array(I, dtype=\"float32\")\n",
        "[[no,yes]] = tumorNet.predict(I, batch_size = 20)\n",
        "if yes>no:\n",
        "  print(\"Tumor detected, with probabilty of \" + str(yes*100) + \"%\")\n",
        "else:\n",
        "  print(\"No tumor detected, with probabilty of \" + str(no*100) + \"%\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-40b07a21-4f7c-4bde-adab-f4b290659a2e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-40b07a21-4f7c-4bde-adab-f4b290659a2e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving pred14.jpg to pred14.jpg\n",
            "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd180968b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Tumor detected, with probabilty of 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}